{
  "hash": "ac0f3ee6ae3c235473854c98992694dc",
  "result": {
    "markdown": "---\ntitle: \"5: Conjugate Families\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-02-13\"\n# format:\n#   revealjs:\n#     scrollable: true\nformat:\n  html:\n    toc: true\n---\n\n\n\\newcommand{\\ds}{\\displaystyle}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"bayesrules\")\nlibrary(\"ggtext\")\nlibrary(\"gt\")\nlibrary(\"patchwork\")\nlibrary(\"tidyverse\")\n\nknitr::opts_chunk$set(echo = TRUE)\n\ntips_df <- readr::read_csv(\"tips.csv\")\n```\n:::\n\n\n# Motivations\n\n## Simple Prior\n\nSuppose that we wanted to estimate a probability $\\pi \\in [0,1]$, but perhaps the beta distribution seems complicated.  Instead, we can try an elementary math function like $f(\\pi) = 3\\pi^{2}$, where this is a probability density function since\n\n$$\\ds\\int_{0}^{1} \\! 3\\pi^{2} \\, d\\pi = 1 \\text{ and } f(\\pi) \\geq 0 \\text{ for } \\pi \\in [0,1]$$\n\n## Interpretability\n\n:::: {.panel-tabset}\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\npi <- seq(0, 1, 0.01)\nf_pi <- 3*pi^2\n\ndf_for_line <- data.frame(pi, f_pi)\ndf_for_shade <- df_for_line |>\n  rbind(c(1,0)) #enforce lower-right corner\n\ndf_for_line |>\n  ggplot(aes(x = pi, y = f_pi)) +\n  geom_polygon(data = df_for_shade, fill = \"#E77500\") +\n  geom_line(color = \"#121212\", linewidth = 3) +\n  labs(title = \"<span style='color:#E77500'>Parabolic Prior</span>: f(pi) = 3pi^2\",\n       subtitle = \"left-skew\",\n       caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown()) #use ggtext package\n```\n:::\n\n\n## Interpretation\n\nIf we start with this prior, we are perhaps assuming a situation over $[0,1]$ where we are expecting the event to likely occur:\n\n$$\\text{E}(\\pi) = \\ds\\int_{0}^{1} \\! \\pi \\cdot f(\\pi) \\, d\\pi = \\ds\\frac{3}{4}$$\n\n::::\n\n## Likelihood\n\nSuppose that we observe $Y = 17$ successes in $n = 32$ independent trials, then modeling the likelihood with a binomial model yields\n\n$$L(\\pi|y = 17) = \\binom{32}{17}\\pi^{17}(1-\\pi)^{15} \\text{ for } \\pi \\in [0,1]$$\n\n## Posterior Distribution\n\nRecall that the posterior distribution is proportional to the product of the prior distribution and the likelihood\n\n$$\\begin{array}{rcl}\n  f(\\pi|y=17) & \\propto & f(\\pi) \\cdot L(\\pi|y=17) \\\\\n  ~ & \\propto & \\pi^{2} \\cdot \\pi^{17}(1-\\pi)^{15} \\\\\n\\end{array}$$\n\n*does not have the same form* as our prior $f(\\pi) = 3\\pi^{2}$\n\n## Normalizing Constant\n\n$$f(\\pi|y=17) = \\ds\\frac{\\pi^{19}(1-\\pi)^{15}}{ \\int_{0}^{1} \\! \\pi^{19}(1-\\pi)^{15} \\, d\\pi } \\text{ for } \\pi \\in [0,1]$$\n\n* integrals can be tough to compute, even with numerical methods\n* very low interpretability\n* difficult to compute sample statistics for the posterior distribution (such as mean and variance)\n\n\n## Conjugate Priors\n\nConjugate families have both computational ease and interpretable posterior distributions.\n\n::: {.callout-note collapse=\"true\"}\n## Conjugate Priors\n\nLet the prior model for parameter $\\theta$ have pdf $f(\\theta)$ and the model of data Y conditioned on $\\theta$ have likelihood function $L(\\theta|y)$. If the resulting posterior model with pdf $f(\\theta|y) \\propto f(\\theta)L(\\theta|y)$ is of the same model family as the prior, then we say this is a **conjugate prior**.\n:::\n\n# Poisson Model\n\n## Poisson Process\n\n:::: {.panel-tabset}\n\n## Motivation\n\n- Assume a constant \\textit{rate parameter} $\\lambda$ of arrivals\n- Let $N_{t}$ be the number of arrivals in time interval $[0,t]$\n- Homogeneity:  $\\text{E}[N_{t}] = \\lambda t$ (``rate times time'')\n- Independence: numbers of arrivals in disjoint time intervals are independent random variables\n\n## Goal\n\nerive distribution of number of arrivals\n\n- We expect $\\text{E}[N_{t}] = \\lambda t$ (``rate times time'')\n- Partition time interval $[0,t]$ into $n$ subintervals\n- Assuming $n$ is large enough so that each subinterval has zero or one arrival (i.e. Bernoulli trial)\n- Probability of arrival in a random subinterval: $p = \\ds\\frac{\\lambda t}{n}$\n\nSo far, we are assuming $N_{t} \\sim \\text{Bin}(n,p)$\n\n$$P(N_{t} = k) = \\binom{n}{k} \\left(\\ds\\frac{\\lambda t}{n}\\right)^{k} \\left(1 - \\ds\\frac{\\lambda t}{n}\\right)^{n-k}$$\n\n## Infinitessimal\n\nHowever,\n\n- $n$ was arbitrary\n- time is a continuous variable\n\nSo let's take the limit as $n$ goes to infinity.\n\n$$\\ds\\lim_{n \\to \\infty} P(N_{t} = k) = \\ds\\lim_{n \\to \\infty} {\\color{purple}\\binom{n}{k} \\left(\\ds\\frac{\\lambda t}{n}\\right)^{k}} {\\color{blue}\\left(1 - \\ds\\frac{\\lambda t}{n}\\right)^{n}} {\\color{red}\\left(1 - \\ds\\frac{\\lambda t}{n}\\right)^{-k}}$$\n\n## Partial Proof\n\nHandling the limit by its factors:\n$$\\ds\\lim_{n \\to \\infty} {\\color{red}\\left(1 - \\ds\\frac{\\lambda t}{n}\\right)^{-k}} = 1, \\quad \\ds\\lim_{n \\to \\infty} {\\color{blue}\\left(1 - \\ds\\frac{\\lambda t}{n}\\right)^{n}} = e^{-\\lambda t}$$\n\n$$\\begin{array}{rcl}\n  \\ds\\lim_{n \\to \\infty} {\\color{purple}\\binom{n}{k} \\left(\\ds\\frac{\\lambda t}{n}\\right)^{k}} & = & (\\lambda t)^{k} \\ds\\lim_{n \\to \\infty} \\binom{n}{k} \\left(\\ds\\frac{1}{n}\\right)^{k} \\\\\n  ~ & = & (\\lambda t)^{k} \\ds\\lim_{n \\to \\infty} \\ds\\frac{n!}{k!(n-k)!} \\cdot \\ds\\frac{1}{n^{k}} \\\\\n  ~ & = & \\ds\\frac{(\\lambda t)^{k}}{k!} \\ds\\lim_{n \\to \\infty} \\ds\\frac{n!}{(n-k)!} \\cdot \\ds\\frac{1}{n^{k}} \\\\\n  ~ & = & \\ds\\frac{(\\lambda t)^{k}}{k!} \\ds\\lim_{n \\to \\infty} \\ds\\prod_{i = 0}^{k-1} \\ds\\frac{n - i}{n} \\\\\n  ~ & = & \\ds\\frac{(\\lambda t)^{k}}{k!}  \\ds\\prod_{i = 0}^{k-1} \\ds\\lim_{n \\to \\infty} \\ds\\frac{n - i}{n} \\\\\n  ~ & = & \\ds\\frac{(\\lambda t)^{k}}{k!}  \\\\\n\\end{array}$$\n\n::::\n\n## Poisson Distribution\n\nLet discrete random variable $Y$ be the number of independent events that occur in a fixed amount of time or space, where $\\lambda>0$ is the rate at which these events occur. Then the dependence of $Y$ on parameter $\\lambda$ can be modeled by the Poisson.\n\n$$Y|\\lambda \\sim \\text{Pois}(\\lambda)$$\n\nwith probability mass function\n\n$$f(y|\\lambda) = \\ds\\frac{\\lambda^{y}e^{-\\lambda}}{y!} \\text{ for } y \\in \\{0, 1, 2, ...\\}$$\n\n* $f(y|\\lambda) \\geq 0$\n* $\\ds\\sum_{y=0}^{\\infty} \\! f(y|\\lambda) = 1$\n\n::: {.callout-note collapse=\"true\"}\n## Statistics\n\nThe Poisson distribution has the curious property where the randomness has equal mean and variance:\n\n$$\\text{E}(Y|\\lambda) = \\text{Var}(Y|\\lambda) = \\lambda$$\n:::\n\n## Guidance\n\n:::: {.panel-tabset}\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_i <- 0:10\nf_y <- dpois(y_i, 1)\ndf_for_plots <- data.frame(y_i,f_y)\n\np1 <- df_for_plots |> \n  ggplot(aes(x = y_i, y = dpois(y_i, 1))) + \n  geom_col() + \n  labs(title = \"lambda = 1\") +\n  scale_x_continuous(name = \"y\", \n                   breaks = 0:10, \n                   labels = as.character(0:10)) +\n  theme_minimal()\n\np2 <- df_for_plots |> \n  ggplot(aes(x = y_i, y = dpois(y_i, 2))) + \n  geom_col() + \n  labs(title = \"lambda = 2\") +\n  scale_x_continuous(name = \"y\", \n                   breaks = 0:10, \n                   labels = as.character(0:10)) +\n  theme_minimal()\n\np3 <- df_for_plots |> \n  ggplot(aes(x = y_i, y = dpois(y_i, 3))) + \n  geom_col() + \n  labs(title = \"lambda = 3\") +\n  scale_x_continuous(name = \"y\", \n                   breaks = 0:10, \n                   labels = as.character(0:10)) +\n  theme_minimal()\n\np4 <- df_for_plots |> \n  ggplot(aes(x = y_i, y = dpois(y_i, 4))) + \n  geom_col() + \n  labs(title = \"lambda = 4\") +\n  scale_x_continuous(name = \"y\", \n                   breaks = 0:10, \n                   labels = as.character(0:10)) +\n  theme_minimal()\n\np5 <- df_for_plots |> \n  ggplot(aes(x = y_i, y = dpois(y_i, 5))) + \n  geom_col() + \n  labs(title = \"lambda = 5\") +\n  scale_x_continuous(name = \"y\", \n                   breaks = 0:10, \n                   labels = as.character(0:10)) +\n  theme_minimal()\n\n# patchwork\np1 + p2 + p3 + p4 + p5\n```\n:::\n\n\n## Guidance\n\nThe Poisson distribution is a discrete distribution that tends to be used to model rare events.\n\n::::\n\n## Joint PMF\n\nLet $(Y_1,Y_2,…,Y_n)$ be an *independent* sample of random variables and $\\vec{y} = (y_1,y_2,…,y_n)$ be the corresponding vector of observed values.\n\n::: {.callout-note collapse=\"true\"}\n## Joint Probability Mass Function\n\nFurther, let $f(y_i|\\lambda)$ denote the pmf of an individual observed data point $Y_i=y_i$. Then by the assumption of independence, the following joint pmf specifies the randomness in and plausibility of the collective sample:\n\n$$f(\\vec{y}|\\lambda) = \\ds\\prod_{i=1}^{n} f(y_{i}|\\lambda) = f(y_{1}|\\lambda) \\cdot (y_{2}|\\lambda) \\cdots f(y_{n}|\\lambda)$$\n:::\n\nThe Poisson probability mass function is then\n\n$$\\begin{array}{rcl}\n  f(\\vec{y}|\\lambda) & = & \\ds\\prod_{i=1}^{n} f(y_{i}|\\lambda) \\\\\n  ~ & = & \\ds\\prod_{i=1}^{n} \\ds\\frac{\\lambda^{y_{i}}e^{\\lambda}}{y_{i}!} \\\\\n  ~ & = & \\ds\\frac{\\lambda^{y_{1}}e^{\\lambda}}{y_{1}!} \\cdot \\ds\\frac{\\lambda^{y_{2}}e^{\\lambda}}{y_{2}!} \\cdots \\ds\\frac{\\lambda^{y_{n}}e^{\\lambda}}{y_{n}!} \\\\\n  ~ & = & \\ds\\frac{ [\\lambda^{y_{1}}\\lambda^{y_{2}}\\cdots\\lambda^{y_{n}}][e^{-\\lambda}e^{-\\lambda} \\cdots e^{-\\lambda}] }{ y_{1}!y_{2}! \\cdots y_{n}! } \\\\\n  ~ & = & \\ds\\frac{\\lambda^{\\sum y_{i}}e^{-n\\lambda}}{\\prod y_{i}!} \\\\\n\\end{array}$$\n\n## Poisson Likelihood\n\nThe Poisson likelihood function is then\n\n$$L(\\lambda|\\vec{y}) = \\ds\\frac{\\lambda^{\\sum y_{i}}e^{-n\\lambda}}{\\prod y_{i}!}$$\n\n## Parameter Selection\n\nHow do we fit a Poisson model with our data? One idea is to seek the *maximum likelihood estimate* (MLE).\n\n**Claim:** The MLE for the $\\text{Pois}(\\lambda)$ distribution is\n$$\\lambda^{*} = \\bar{y} = \\ds\\frac{\\sum y_{i}}{n}$$\n\n::: {.callout-note collapse=\"true\"}\n## Proof\n\nFrom the Poisson distribution's PMF $f(y) = \\ds\\frac{\\lambda^{y}e^{-\\lambda}}{y!}$, the likelihood function\n\n$$L(\\lambda) = \\ds\\frac{\\lambda^{y_{1}}e^{-\\lambda}}{y_{1}!} \\cdot \\ds\\frac{\\lambda^{y_{2}}e^{-\\lambda}}{y_{2}!} \\cdots \\ds\\frac{\\lambda^{y_{n}}e^{-\\lambda}}{y_{n}!} $$\n\nTaking the natural logarithm of both sides, we create the **log likelihood** function $\\ell(\\lambda)$\n\n$$\\begin{array}{rcl}\n  \\ln L(\\lambda) & = & \\ln \\left(\\ds\\frac{\\lambda^{y_{1}}e^{-\\lambda}}{y_{1}!} \\cdot \\ds\\frac{\\lambda^{y_{2}}e^{-\\lambda}}{y_{2}!} \\cdots \\ds\\frac{\\lambda^{y_{n}}e^{-\\lambda}}{y_{n}!}\\right) \\\\\n  \\ell(\\lambda) & = & \\ln \\ds\\prod_{i=1}^{n} \\ds\\frac{\\lambda^{y_{i}}e^{-\\lambda}}{y_{i}!} \\\\\n  \\ell(\\lambda) & = & \\ds\\sum_{i=1}^{n} \\ln \\ds\\frac{\\lambda^{y_{i}}e^{-\\lambda}}{y_{i}!} \\\\\n  \n  \\ell(\\lambda) & = & \\ds\\sum_{i=1}^{n} \\left( y_{i}\\ln \\lambda + \\ln e^{-\\lambda} - \\ln y_{i}! \\right) \\\\\n  \n  \\ell(\\lambda) & = & (\\ln \\lambda)\\left(\\ds\\sum_{i=1}^{n} y_{i}\\right) -  \\ds\\sum_{i=1}^{n}\\lambda -  \\ds\\sum_{i=1}^{n} \\ln y_{i}! \\\\\n  \n  \\ell(\\lambda) & = &  (\\ln \\lambda)\\left(\\ds\\sum_{i=1}^{n} y_{i}\\right) - n\\lambda - \\ds\\sum_{i=1}^{n} \\ln (y_{i}!) \\\\\n\\end{array}$$\n\nThe motivation for the logarithm usage is to ease the process of taking the derivative.  Here, taking the derivative with respect to $\\lambda$, \n\n$$0 = \\ell'(\\lambda)  \\quad\\Rightarrow\\quad 0 = -n + \\ds\\frac{ \\sum_{i=1}^{n} y_{i} }{ \\lambda } \\quad\\Rightarrow\\quad \\lambda = \\ds\\frac{ \\sum_{i=1}^{n} y_{i} }{ n } = \\bar{y}$$\n\nThat is, the optimal value for parameter $\\lambda$ is the sample mean $\\bar{y}$.\n:::\n\n## Example: Campus Safety\n\n:::: {.panel-tabset}\n\n## Data\n\nThe following data on arrests for drug law violations come from the Princeton University [Annual Security and Fire Safety Report](https://publicsafety.princeton.edu/information/monthlyannual-data)  (in and around the main campus)\n\n|   year  | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 | 2020 | 2021 | 2022 |\n|:-------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n| arrests |  18  |  14  |  23  |  22  |  12  |  22  |   7  |   0  |   1  |\n\nOur maximum likelihood estimate is\n\n$$\\lambda^{*} = \\ds\\frac{\\sum y_{i}}{n} = \\ds\\frac{119}{9} \\approx 13.2222 \\text{ arrests per year}$$\n\n## Likelihood\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::plot_poisson_likelihood(\n  y = c(18, 14, 23, 22, 12, 22, 7, 0, 1),\n  lambda_upper_bound = 20\n) +\n  labs(title = \"Likelihood Curve\",\n       subtitle = \"Arrests per year for drug law violations\",\n       caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n::::\n\n\n# Gamma Model\n\n## Terminology\n\nLet $\\lambda > 0$ be a continuous random variable. For modeling, we might try a Gamma model\n$$\\lambda \\sim \\text{Gamma}(s, r)$$\n\n* $s$: shape parameter\n* $r$: rate parameter\n\n::: {.callout-tip collapse=\"true\"}\n\n## Explore! \n\nMatt Bognar at the University of Iowa created this [great webapp](https://homepage.divms.uiowa.edu/~mbognar/applets/gamma.html) to explore the gamma distribution.\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Exponential Model\n\nThe Gamma model is a generalization of the exponential model.  When the shape parameter $s = 1$, then\n\n$$\\lambda \\sim \\text{Gamma}(1,r) = \\text{Exp}(r)$$\n\nwhere $r$ is once again the rate parameter.\n:::\n\n## Probablity Density Function\n\nThe Gamma model has a continuous pdf\n\n$$f(\\lambda) = \\ds\\frac{r^{s}}{\\Gamma(s)} \\lambda^{s-1}e^{-r\\lambda} \\text{ for } \\lambda > 0$$\n\nwhere the gamma function\n\n* $\\Gamma(z) = \\ds\\int_{0}^{\\infty} \\! x^{z-1}e^{-x} \\, dx$\n\n::: {.callout-note collapse=\"true\"}\n## Statistics\n\nFormulas for the Gamma model include\n\n$$\\begin{array}{rcl}\n  \\text{E}(\\lambda) & = & \\ds\\frac{s}{r} \\\\\n  \\text{Mode}(\\lambda) & = & \\ds\\frac{s-1}{r} \\\\\n  \\text{Var}(\\lambda) & = & \\ds\\frac{s}{r^{2}} \\\\\n\\end{array}$$\n:::\n\n## Tuning the Prior\n\n:::: {.panel-tabset}\n\n## Example: Campus Safety\n\nSuppose that a parent of an university applicant feels that the university has arrests for drug law violations with counts between 10 and 30 per year.  Matching some statistics formulas\n\n$$[\\mu - 2\\sigma, \\mu + 2\\sigma] = [10, 30] \\quad\\rightarrow\\quad \\mu = 20, \\quad \\sigma = 5$$\n\n## Statistics\n\n$$\\text{E}(\\lambda) = \\ds\\frac{s}{r} = 20 \\text{ and } \\text{Var}(\\lambda) = \\ds\\frac{s}{r^{2}} = 5^{2}$$\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::plot_gamma(16, 0.8, mean = TRUE) +\n  labs(title = \"Gamma(16, 0.8) Prior\",\n       subtitle = \"mean = 20, sd = 5\",\n       caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n::::\n\n\n# Gamma-Poisson Conjugate Family\n\n## Gamma-Poisson Bayesian Model\n\nLet $\\lambda > 0$ be an unknown rate parameter and let $\\{Y_{1}, Y_{2}, ..., Y_{n}\\}$ be an i.i.d. sample from a $\\text{Pois}(\\lambda)$ distribution.  With a setup of a Gamma prior and Poisson likelihood\n\n$$\\begin{array}{rcl}\n  \\lambda & \\sim & \\text{Gamma}(s,r) \\\\\n  Y_{i}|\\lambda & \\sim & \\text{Pois}(\\lambda) \\\\\n\\end{array}$$\n\nand observing data $\\vec{y} = \\{y_{1}, y_{2}, ..., y_{n}\\}$, the posterior distribution also has a Gamma structure with updated parameters\n\n$$\\lambda|\\vec{y} \\sim \\text{Gamma}\\left( s + \\ds\\sum_{i=1}^{n} y_{i}, r + n \\right)$$\n\n::: {.callout-note collapse=\"true\"}\n## Proof\n\n$$\\begin{array}{rcl}\n  f(\\lambda|\\vec{y}) & \\propto & f(\\lambda) \\cdot L(\\lambda|\\vec{y}) \\\\\n  ~ & = & \\ds\\frac{r^{s}}{\\Gamma(s)}\\lambda^{s-1}e^{-r\\lambda} \\cdot \\ds\\frac{\\lambda^{\\sum y_{i}}e^{-n\\lambda}}{\\prod y_{i}!} \\\\\n  ~ & \\propto & \\lambda^{s-1}e^{-r\\lambda} \\cdot \\lambda^{\\sum y_{i}}e^{-n\\lambda} \\\\\n  ~ & = & \\lambda^{s+\\sum y_{i} - 1}e^{-(r+n)\\lambda} \\\\\n\\end{array}$$\n:::\n\n## Example: Campus Safety\n\n:::: {.panel-tabset}\n\n## Recap\n\n* we tuned a $\\text{Gamma}(16, 0.8)$ prior\n* we observed 119 arrests for drug law violations over a $n = 9$ year time span\n\n## Plots\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::plot_gamma_poisson(shape = 16, rate = 0.8,\n                               sum_y = 119, n = 9) +\n  labs(title = \"Gamma-Poisson Model\",\n       subtitle = \"Drug Law Violations Example\",\n       caption = \"SML 320\",\n       x = \"arrests for drug law violations\") +\n  theme_minimal()\n```\n:::\n\n\n## Statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::summarize_gamma_poisson(shape = 16, rate = 0.8,\n                                    sum_y = 119, n = 9) |>\n  mutate_if(is.numeric, round, digits = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      model shape rate    mean    mode     var     sd\n1     prior    16  0.8 20.0000 18.7500 25.0000 5.0000\n2 posterior   135  9.8 13.7755 13.6735  1.4057 1.1856\n```\n:::\n:::\n\n\n\n::::\n\n\n# Normal-Normal\n\n## Terminology\n\nLet $Y > 0$ be a continuous random variable over all real numbers $())-\\infty, \\infty)$. For modeling, we might try a normal distribution\n$$Y \\sim \\text{N}(\\mu, \\sigma^{2})$$\n\n* $\\mu$: mean\n* $\\sigma$: standard deviation\n\n## Probablity Density Function\n\nThe normal distribution has a continuous probability density function\n\n$$f(y) = \\ds\\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} \\text{exp}\\left[ -\\ds\\frac{(y-\\mu)^{2}}{2\\sigma^{2}}\\right] \\text{ for } y \\in (-\\infty, \\infty)$$\n\n::: {.callout-note collapse=\"true\"}\n## Statistics\n\nDescriptions of normal distributions are dictated by their statistics\n\n$$\\begin{array}{rcl}\n  \\text{E}(Y) & = & \\mu \\\\\n  \\text{Mode}(Y) & = & \\mu \\\\\n  \\text{Var}(Y) & = & \\sigma^{2} \\\\\n  \\text{SD}(Y) & = & \\sigma \\\\\n\\end{array}$$\n\n:::\n\n## Tuning the Prior\n\n:::: {.panel-tabset}\n\n## Example: Tips\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(tips_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  total_bill   tip sex    smoker day   time    size\n       <dbl> <dbl> <chr>  <chr>  <chr> <chr>  <dbl>\n1       17.0  1.01 Female No     Sun   Dinner     2\n2       10.3  1.66 Male   No     Sun   Dinner     3\n3       21.0  3.5  Male   No     Sun   Dinner     3\n4       23.7  3.31 Male   No     Sun   Dinner     2\n5       24.6  3.61 Female No     Sun   Dinner     4\n6       25.3  4.71 Male   No     Sun   Dinner     4\n```\n:::\n:::\n\n\n## Statistics\n\nLet us guess that Americans tend to tip between 5 and 25 percent of the total bill.\n\n$$[\\mu - 2\\sigma, \\mu + 2\\sigma] = [5, 25] \\quad\\rightarrow\\quad \\mu = 15, \\quad \\sigma = 5$$\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::plot_normal(mean = 15, sd = 5) +\n  labs(title = \"N(15, 25) Prior\",\n       subtitle = \"mean = 15, sd = 5\",\n       caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n::::\n\n## Likelihood\n\nIn this conjugate prior relationship, the likelihood is also modeled as a normal distribution.\n\n$$L(\\mu, \\sigma|\\vec{y}) \\propto \\ds\\prod_{i=1}^{n} \\text{exp}\\left[-\\ds\\frac{(y_{i} - \\mu)^{2}}{2\\sigma^{2}}\\right] = \\text{exp}\\left[-\\ds\\frac{\\sum_{i=1}^{n} (y_{i}-\\mu)^{2}}{2\\sigma^{2}}\\right]$$\n\n## MLEs\n\nThe likelihood can also be expressed in terms of the sample mean $\\bar{y}$ and the sample size $n$\n\n$$L(\\mu, \\sigma|\\vec{y}) \\propto \\text{exp}\\left[-\\ds\\frac{ (\\bar{y}-\\mu)^{2}}{\\frac{2\\sigma^{2}}{n}}\\right]$$\n\nIt follows that the maximum likelihood estimates for the parameters are \n\n$$\\begin{array}{rcl}\n  \\mu^{*} & = & \\ds\\frac{1}{n}\\ds\\sum_{i=1}^{n} y_{i} \\\\\n  \\sigma^{*} & = & \\sqrt{\\ds\\frac{1}{n}\\ds\\sum_{i=1}^{n} (y_{i} - \\mu^{2})^{2}} \\\\\n\\end{array}$$\n\nwhich are the sample mean and from the *not-corrected* population variance ([source](https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood)).\n\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- nrow(tips_df)\ntips_df |>\n  mutate(tips_pct = tip/total_bill * 100) |>\n  summarize(mu = mean(tips_pct, na.rm = TRUE),\n            sigma = sqrt(var(tips_pct, na.rm = TRUE) *(n-1)/(n)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n     mu sigma\n  <dbl> <dbl>\n1  16.1  6.09\n```\n:::\n:::\n\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::plot_normal(mean = 16.08026, sd = 6.094693\t) +\n  labs(title = \"Normal \",\n       subtitle = \"MLEs: ybar = 16.08026, sigma = 6.094693\",\n       caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n\n## Normal-Normal Conjugacy\n\nLet $\\mu \\in (-\\infty, \\infty)$ be an unknown mean parameter and let $\\sigma^{2} > 0$ be an unknown variance parameter and let $\\{Y_{1}, Y_{2}, ..., Y_{n}\\}$ be an i.i.d. sample from a $\\text{N}(\\mu, \\sigma^{2})$ distribution.  With a setup of a normal prior and normal likelihood\n\n$$\\begin{array}{rcl}\n  \\mu,\\sigma^{2} & \\sim & \\text{N}(\\theta,\\tau^{2}) \\\\\n  Y_{i}|\\mu, \\sigma^{2} & \\sim & \\text{N}(\\mu,\\sigma^{2}) \\\\\n\\end{array}$$\n\nand observing data $\\vec{y} = \\{y_{1}, y_{2}, ..., y_{n}\\}$, the posterior distribution also has a normal structure with updated parameters\n\n$$\\mu,\\sigma^{2}|\\vec{y} \\sim \\text{N}\\left( \\ds\\frac{\\sigma^{2}}{n\\tau^{2}+\\sigma^{2}} \\cdot \\theta + \\ds\\frac{n\\tau^{2}}{n\\tau^{2}+\\sigma^{2}} \\cdot \\bar{y}, \\quad \\ds\\frac{\\tau^{2}\\sigma^{2}}{n\\tau^{2}+\\sigma^{2}} \\right)$$\n\n* What happens if we have relatively small data sets?\n* What happens if we have relatively large data sets?\n\n## Example\n\n:::: {.panel-tabset}\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::plot_normal_normal(\n  \n  # from prior\n  mean = 15, sd = 5,\n  \n  # from observations\n  y_bar = 16.08026, sigma = 6.094693, n = 244\n) +\n  labs(title = \"Normal-Normal Model\",\n       subtitle = \"Restaurant Tips Example\",\n       caption = \"SML 320\",\n       x = \"percent of total food bill\") +\n  theme_minimal()\n```\n:::\n\n\n## Plots\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_conjugate_families_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## Statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesrules::summarize_normal_normal(\n  \n  # from prior\n  mean = 15, sd = 5,\n  \n  # from observations\n  y_bar = 16.08026, sigma = 6.094693, n = 244\n) |>\n  mutate_if(is.numeric, round, digits = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      model    mean    mode     var    sd\n1     prior 15.0000 15.0000 25.0000 5.000\n2 posterior 16.0737 16.0737  0.1513 0.389\n```\n:::\n:::\n\n\n\n::::\n\n## Model Selection\n\nWe looked at 3 conjugate families.\n\n:::: {.panel-tabset}\n\n## Beta-Binomial\n\n* estimate $\\pi \\in [0,1]$\n* pro: good for interpretability\n* con: computationally expensive for large $n$\n\n## Gamma-Poisson\n\n* estimate $\\lambda > 0$\n* pro: models rare events and skewed data well\n* con: discussion of rates instead of counts\n\n## Normal-Normal\n\n* estimate mean $\\mu$ and variance $\\sigma$\n* pro: ubiquitous in scientific communities\n* cons: \n\n    * infinite support may lead to suboptimal results in larger networks\n    * was the data symmetric?\n\n\n::::\n\n\n\n\n# Footnotes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.0 (2023-04-21 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.2  forcats_1.0.0    stringr_1.5.0    dplyr_1.1.3     \n [5] purrr_1.0.2      readr_2.1.4      tidyr_1.3.0      tibble_3.2.1    \n [9] ggplot2_3.4.3    tidyverse_2.0.0  patchwork_1.1.2  gt_0.9.0        \n[13] ggtext_0.1.2     bayesrules_0.0.2\n\nloaded via a namespace (and not attached):\n  [1] gridExtra_2.3       inline_0.3.19       rlang_1.1.1        \n  [4] magrittr_2.0.3      snakecase_0.11.0    matrixStats_1.0.0  \n  [7] e1071_1.7-13        compiler_4.3.0      loo_2.6.0          \n [10] callr_3.7.3         vctrs_0.6.3         reshape2_1.4.4     \n [13] pkgconfig_2.0.3     crayon_1.5.2        fastmap_1.1.1      \n [16] ellipsis_0.3.2      labeling_0.4.3      utf8_1.2.3         \n [19] threejs_0.3.3       promises_1.2.1      rmarkdown_2.24     \n [22] tzdb_0.4.0          markdown_1.8        ps_1.7.5           \n [25] nloptr_2.0.3        bit_4.0.5           xfun_0.40          \n [28] jsonlite_1.8.7      later_1.3.1         parallel_4.3.0     \n [31] prettyunits_1.1.1   R6_2.5.1            dygraphs_1.1.1.6   \n [34] stringi_1.7.12      StanHeaders_2.26.26 boot_1.3-28.1      \n [37] Rcpp_1.0.11         rstan_2.21.8        knitr_1.43         \n [40] zoo_1.8-12          base64enc_0.1-3     bayesplot_1.10.0   \n [43] httpuv_1.6.11       Matrix_1.5-4        splines_4.3.0      \n [46] igraph_1.4.3        timechange_0.2.0    tidyselect_1.2.0   \n [49] rstudioapi_0.15.0   yaml_2.3.7          codetools_0.2-19   \n [52] miniUI_0.1.1.1      processx_3.8.1      pkgbuild_1.4.0     \n [55] lattice_0.21-8      plyr_1.8.8          withr_2.5.2        \n [58] shiny_1.7.5         groupdata2_2.0.2    evaluate_0.21      \n [61] survival_3.5-5      proxy_0.4-27        RcppParallel_5.1.7 \n [64] xts_0.13.1          xml2_1.3.5          pillar_1.9.0       \n [67] DT_0.28             stats4_4.3.0        shinyjs_2.1.0      \n [70] generics_0.1.3      vroom_1.6.3         hms_1.1.3          \n [73] commonmark_1.9.0    rstantools_2.3.1    munsell_0.5.0      \n [76] scales_1.2.1        minqa_1.2.5         gtools_3.9.4       \n [79] xtable_1.8-4        class_7.3-21        glue_1.6.2         \n [82] janitor_2.2.0       tools_4.3.0         shinystan_2.6.0    \n [85] lme4_1.1-33         colourpicker_1.2.0  grid_4.3.0         \n [88] crosstalk_1.2.0     colorspace_2.1-0    nlme_3.1-162       \n [91] cli_3.6.1           fansi_1.0.4         gtable_0.3.4       \n [94] digest_0.6.33       farver_2.1.1        htmlwidgets_1.6.2  \n [97] htmltools_0.5.6     lifecycle_1.0.4     mime_0.12          \n[100] rstanarm_2.21.4     bit64_4.0.5         gridtext_0.1.5     \n[103] shinythemes_1.2.0   MASS_7.3-58.4      \n```\n:::\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\n:::\n\n::::\n\n:::: {.panel-tabset}\n\n\n\n::::",
    "supporting": [
      "05_conjugate_families_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}