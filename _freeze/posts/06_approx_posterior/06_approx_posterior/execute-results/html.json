{
  "hash": "ab4c0c9c1c5ddae3e18adc179fdd06de",
  "result": {
    "markdown": "---\ntitle: \"6: Approximating the Posterior\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-02-15\"\n# format:\n#   revealjs:\n#     scrollable: true\nformat:\n  html:\n    toc: true\nparams:\n  heavy_chunks: \"true\"\n  # heavy_chunks: \"false\"\n---\n\n\n\\newcommand{\\ds}{\\displaystyle}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"bayesplot\")\nlibrary(\"ggtext\")\nlibrary(\"rstan\")\nlibrary(\"tidyverse\")\n\nknitr::opts_chunk$set(echo = TRUE)\n\n# tips_df <- readr::read_csv(\"tips.csv\")\n```\n:::\n\n\n# Multivariate Data\n\n##  Setting: NOAA\n\nI will be studying weather data for a semester theme.  The main data will probably come from [NOAA](https://www.noaa.gov/) (National Oceanic and Atmospheric Administration), where the data consists of several readings (variables) from several research stations over many years.\n\nLet $\\theta$ represent the high temperature recorded.  Across $k$ research stations,\n\n$$\\vec{\\theta} = (\\theta_{1}, \\theta_{2}, ..., \\theta_{k})$$\n\n## Bayesian Approach\n\nIf we have a vector of parameters to estimate,\n\n$$f(\\vec{\\theta} | \\vec{y} ) \\propto \\text{prior}*\\text{likelihood} = f(\\vec{\\theta}) \\cdot L(\\vec{\\theta} | \\vec{y})$$\n\n## Normalizing Constant\n\n$$f(y) = \\ds\\int_{\\theta_{1}}\\int_{\\theta_{2}} \\cdots \\int_{\\theta_{k}} \\! f(\\vec{\\theta}) \\cdot L(\\vec{\\theta} | \\vec{y} ) \\, d\\theta_{k} \\cdots d\\theta_{2} \\, d\\theta_{1}$$\n\n* closed form solution probably does not exist\n* very expensive computationally\n\n\n# Strategy\n\n*Approximate* the posterior distribution via simulation\n\n* grid approximation, or\n* MCMC (Monte Carlo Markov Chains)\n\nBoth produce a **sample** of $N$ $\\theta$ values\n\n$$\\{ \\theta^{(1)}, \\theta^{(2)}, ..., \\theta^{(N)} \\}$$\n\nthat may have similar statistics to the posterior distribution of $\\theta$.\n\n## Conjugate Priors\n\nFor today, we will revisit the conjugate priors where we know a lot about the posterior distributions.\n\n* Beta-Binomial\n\n$$\\begin{array}{rrcl}\n  \\text{prior: } & \\pi & \\sim & \\text{Beta}(\\alpha, \\beta) \\\\\n  \\text{likelihood: } & Y|\\pi & \\sim & \\text{Bin}(n, \\pi) \\\\\n  \\text{posterior: } & \\pi|Y & \\sim & \\text{Beta}(\\alpha + y, \\beta + n - y) \\\\\n\\end{array}$$\n\n* Gamma-Poisson\n\n$$\\begin{array}{rrcl}\n  \\text{prior: } & \\pi & \\sim & \\text{Gamma}(s, r) \\\\\n  \\text{likelihood: } & Y|\\pi & \\sim & \\text{Pois}(\\lambda) \\\\\n  \\text{posterior: } & \\pi|Y & \\sim & \\text{Gamma}\\left(s + \\ds\\sum_{i=1}^{n} y, r + n\\right) \\\\\n\\end{array}$$\n\n\n# Grid Approximation\n\n## Broad Idea\n\nAs we gather pieces, the overall picture might become clear.\n\n![Art of Ellis Rowan](ellis_rowan_puzzle_video.gif)\n\n* image source: [National Museum of Australia](https://www.nla.gov.au/stories/news/2020/puzzles-using-collection)\n\n## Math Definitions\n\nGrid approximation produces a sample of $N$ independent $\\theta$ values, $\\{\\theta^(1),\\theta^(2),â€¦,\\theta^(N)\\}$, from a discretized approximation of posterior pdf $f(\\theta|y)$. This algorithm evolves in four steps:\n\n1. Define a discrete grid of possible $\\theta$ values.\n2. Evaluate the prior pdf $f(\\theta)$ and likelihood function $L(\\theta|y)$ at each $\\theta$ grid value.\n3. Obtain a discrete approximation of the posterior pdf $f(\\theta|y)$\nby: \n\n    (a) calculating the product $f(\\theta)L(\\theta|y)$ at each $\\theta$ grid value; and then \n    (b) normalizing the products so that they sum to 1 across all $\\theta$.\n4. Randomly sample $N$ $\\theta$ grid values with respect to their corresponding normalized posterior probabilities.\n\n\n## Example: Beta-Binomial\n\n### Scenario: Smokers in Restaurants\n\nLet us start with a vague beta prior, use a binomial model to get the likelihood of $y = 4$ smokers among $n = 9$ customers, and then get a beta posterior.\n\n$$\\begin{array}{rrcl}\n  \\text{prior: } & \\pi & \\sim & \\text{Beta}(3, 3) \\\\\n  \\text{likelihood: } & Y|\\pi & \\sim & \\text{Bin}(9, \\pi) \\\\\n  \\text{posterior: } & \\pi|Y & \\sim & \\text{Beta}(7, 8) \\\\\n\\end{array}$$\n\n## Sparse Grid\n\nHere we will try this grid approximation idea over $N = 5$ values\n\n$$\\pi \\in \\{0, 0.25, 0.50, 0.75, 1.0\\}$$\n\n:::: {.panel-tabset}\n\n## Bayes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Define a grid of 6 pi values\ngrid_data <- data.frame(pi_grid = seq(from = 0, to = 1, \n                                      length = 5))\n\n# Step 2: Evaluate the prior & likelihood at each pi\ngrid_data <- grid_data %>% \n  mutate(prior = dbeta(pi_grid, 3, 3),\n         likelihood = dbinom(4, 9, pi_grid))\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n```\n:::\n\n\n## Grid Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(grid_data, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pi_grid  prior likelihood unnormalized posterior\n1    0.00 0.0000     0.0000       0.0000    0.0000\n2    0.25 1.0547     0.1168       0.1232    0.1969\n3    0.50 1.8750     0.2461       0.4614    0.7375\n4    0.75 1.0547     0.0389       0.0411    0.0656\n5    1.00 0.0000     0.0000       0.0000    0.0000\n```\n:::\n:::\n\n\n## Grid Values\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Graph 1 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the grid approximated posterior\nggplot(grid_data, aes(x = pi_grid, y = posterior)) + \n  geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior),\n               color = \"gray50\",\n               linewidth = 2) +\n  geom_point(size = 7) + \n  labs(title = \"Sparse Grid\",\n         subtitle = \"Beta-Binomial Example\",\n         caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n## Posterior Sampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 4: sample from the discretized posterior\nposterior_sample <- sample_n(grid_data, \n                             size = 10000, \n                             weight = posterior, \n                             replace = TRUE)\n```\n:::\n\n\n## Alignment\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n## Graph 2 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(posterior_sample, aes(x = pi_grid)) + \n  geom_histogram(aes(y = after_stat(density)), \n                 binwidth = 0.1,\n                 fill = \"gray50\") + \n  stat_function(fun = dbeta, args = list(7, 8),\n                color = \"#E77500\", linewidth = 3) + \n  lims(x = c(0, 1)) +\n  labs(title = \"Sparse Grid: <span style='color:#7F7F7F'>simulation</span> versus <span style='color:#E77500'>theoretical</span>\",\n         subtitle = \"Beta-Binomial Example\",\n         caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown())\n```\n:::\n\n\n::::\n\n\n## Dense Grid\n\nHere we will try this grid approximation idea over $N = 101$ values\n\n$$\\pi \\in [0,1]$$\n\n:::: {.panel-tabset}\n\n## Bayes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Define a grid of 6 pi values\ngrid_data <- data.frame(pi_grid = seq(from = 0, to = 1, \n                                      length = 101))\n\n# Step 2: Evaluate the prior & likelihood at each pi\ngrid_data <- grid_data %>% \n  mutate(prior = dbeta(pi_grid, 3, 3),\n         likelihood = dbinom(4, 9, pi_grid))\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n```\n:::\n\n\n## Grid Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(grid_data, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    pi_grid  prior likelihood unnormalized posterior\n1      0.00 0.0000     0.0000       0.0000    0.0000\n2      0.01 0.0029     0.0000       0.0000    0.0000\n3      0.02 0.0115     0.0000       0.0000    0.0000\n4      0.03 0.0254     0.0001       0.0000    0.0000\n5      0.04 0.0442     0.0003       0.0000    0.0000\n6      0.05 0.0677     0.0006       0.0000    0.0000\n7      0.06 0.0954     0.0012       0.0001    0.0000\n8      0.07 0.1271     0.0021       0.0003    0.0000\n9      0.08 0.1625     0.0034       0.0006    0.0000\n10     0.09 0.2012     0.0052       0.0010    0.0001\n11     0.10 0.2430     0.0074       0.0018    0.0001\n12     0.11 0.2875     0.0103       0.0030    0.0002\n13     0.12 0.3345     0.0138       0.0046    0.0003\n14     0.13 0.3837     0.0179       0.0069    0.0004\n15     0.14 0.4349     0.0228       0.0099    0.0006\n16     0.15 0.4877     0.0283       0.0138    0.0009\n17     0.16 0.5419     0.0345       0.0187    0.0012\n18     0.17 0.5973     0.0415       0.0248    0.0016\n19     0.18 0.6536     0.0490       0.0320    0.0020\n20     0.19 0.7106     0.0573       0.0407    0.0026\n21     0.20 0.7680     0.0661       0.0507    0.0032\n22     0.21 0.8257     0.0754       0.0623    0.0040\n23     0.22 0.8834     0.0852       0.0753    0.0048\n24     0.23 0.9409     0.0954       0.0898    0.0057\n25     0.24 0.9981     0.1060       0.1058    0.0067\n26     0.25 1.0547     0.1168       0.1232    0.0078\n27     0.26 1.1105     0.1278       0.1419    0.0090\n28     0.27 1.1655     0.1388       0.1618    0.0103\n29     0.28 1.2193     0.1499       0.1827    0.0116\n30     0.29 1.2718     0.1608       0.2045    0.0130\n31     0.30 1.3230     0.1715       0.2269    0.0144\n32     0.31 1.3726     0.1820       0.2498    0.0159\n33     0.32 1.4205     0.1921       0.2729    0.0173\n34     0.33 1.4666     0.2017       0.2959    0.0188\n35     0.34 1.5107     0.2109       0.3185    0.0202\n36     0.35 1.5527     0.2194       0.3406    0.0216\n37     0.36 1.5925     0.2272       0.3619    0.0230\n38     0.37 1.6301     0.2344       0.3820    0.0243\n39     0.38 1.6652     0.2407       0.4008    0.0255\n40     0.39 1.6979     0.2462       0.4180    0.0266\n41     0.40 1.7280     0.2508       0.4334    0.0275\n42     0.41 1.7555     0.2545       0.4468    0.0284\n43     0.42 1.7802     0.2573       0.4581    0.0291\n44     0.43 1.8022     0.2592       0.4671    0.0297\n45     0.44 1.8214     0.2601       0.4737    0.0301\n46     0.45 1.8377     0.2600       0.4779    0.0304\n47     0.46 1.8511     0.2590       0.4795    0.0305\n48     0.47 1.8615     0.2571       0.4786    0.0304\n49     0.48 1.8690     0.2543       0.4753    0.0302\n50     0.49 1.8735     0.2506       0.4695    0.0298\n51     0.50 1.8750     0.2461       0.4614    0.0293\n52     0.51 1.8735     0.2408       0.4511    0.0287\n53     0.52 1.8690     0.2347       0.4387    0.0279\n54     0.53 1.8615     0.2280       0.4245    0.0270\n55     0.54 1.8511     0.2207       0.4085    0.0260\n56     0.55 1.8377     0.2128       0.3910    0.0248\n57     0.56 1.8214     0.2044       0.3722    0.0237\n58     0.57 1.8022     0.1955       0.3524    0.0224\n59     0.58 1.7802     0.1863       0.3317    0.0211\n60     0.59 1.7555     0.1769       0.3105    0.0197\n61     0.60 1.7280     0.1672       0.2889    0.0184\n62     0.61 1.6979     0.1574       0.2673    0.0170\n63     0.62 1.6652     0.1475       0.2457    0.0156\n64     0.63 1.6301     0.1376       0.2244    0.0143\n65     0.64 1.5925     0.1278       0.2036    0.0129\n66     0.65 1.5527     0.1181       0.1834    0.0117\n67     0.66 1.5107     0.1086       0.1641    0.0104\n68     0.67 1.4666     0.0994       0.1457    0.0093\n69     0.68 1.4205     0.0904       0.1284    0.0082\n70     0.69 1.3726     0.0818       0.1122    0.0071\n71     0.70 1.3230     0.0735       0.0973    0.0062\n72     0.71 1.2718     0.0657       0.0835    0.0053\n73     0.72 1.2193     0.0583       0.0711    0.0045\n74     0.73 1.1655     0.0513       0.0598    0.0038\n75     0.74 1.1105     0.0449       0.0499    0.0032\n76     0.75 1.0547     0.0389       0.0411    0.0026\n77     0.76 0.9981     0.0335       0.0334    0.0021\n78     0.77 0.9409     0.0285       0.0268    0.0017\n79     0.78 0.8834     0.0240       0.0212    0.0013\n80     0.79 0.8257     0.0200       0.0165    0.0011\n81     0.80 0.7680     0.0165       0.0127    0.0008\n82     0.81 0.7106     0.0134       0.0095    0.0006\n83     0.82 0.6536     0.0108       0.0070    0.0004\n84     0.83 0.5973     0.0085       0.0051    0.0003\n85     0.84 0.5419     0.0066       0.0036    0.0002\n86     0.85 0.4877     0.0050       0.0024    0.0002\n87     0.86 0.4349     0.0037       0.0016    0.0001\n88     0.87 0.3837     0.0027       0.0010    0.0001\n89     0.88 0.3345     0.0019       0.0006    0.0000\n90     0.89 0.2875     0.0013       0.0004    0.0000\n91     0.90 0.2430     0.0008       0.0002    0.0000\n92     0.91 0.2012     0.0005       0.0001    0.0000\n93     0.92 0.1625     0.0003       0.0000    0.0000\n94     0.93 0.1271     0.0002       0.0000    0.0000\n95     0.94 0.0954     0.0001       0.0000    0.0000\n96     0.95 0.0677     0.0000       0.0000    0.0000\n97     0.96 0.0442     0.0000       0.0000    0.0000\n98     0.97 0.0254     0.0000       0.0000    0.0000\n99     0.98 0.0115     0.0000       0.0000    0.0000\n100    0.99 0.0029     0.0000       0.0000    0.0000\n101    1.00 0.0000     0.0000       0.0000    0.0000\n```\n:::\n:::\n\n\n## Grid Values\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Graph 1 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the grid approximated posterior\nggplot(grid_data, aes(x = pi_grid, y = posterior)) + \n  geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior),\n               color = \"gray50\",\n               linewidth = 1) +\n  geom_point(size = 2) + \n  labs(title = \"Dense Grid\",\n         subtitle = \"Beta-Binomial Example\",\n         caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n## Posterior Sampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 4: sample from the discretized posterior\nposterior_sample <- sample_n(grid_data, \n                             size = 10000, \n                             weight = posterior, \n                             replace = TRUE)\n```\n:::\n\n\n## Alignment\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Graph 2 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(posterior_sample, aes(x = pi_grid)) + \n  geom_histogram(aes(y = after_stat(density)), \n                 color = \"black\", \n                 binwidth = 0.05,\n                 fill = \"gray50\") + \n  stat_function(fun = dbeta, args = list(7, 8),\n                color = \"#E77500\", linewidth = 3) + \n  lims(x = c(0, 1)) +\n  labs(title = \"Dense Grid: <span style='color:#7F7F7F'>simulation</span> versus <span style='color:#E77500'>theoretical</span>\",\n         subtitle = \"Beta-Binomial Example\",\n         caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown())\n```\n:::\n\n\n::::\n\n\n## Example: Gamma-Poisson\n\n### Scenario: Drug Law Violations\n\nLet us start with a vague Gamma prior, use a binomial model to get the likelihood of $\\sum y = 119$ drug law violations over $n = 9$ years, and then get a Gamma posterior.\n\n$$\\begin{array}{rrcl}\n  \\text{prior: } & \\pi & \\sim & \\text{Gamma}(16, 0.8) \\\\\n  \\text{likelihood: } & Y|\\pi & \\sim & \\text{Pois}(119/9) \\\\\n  \\text{posterior: } & \\pi|Y & \\sim & \\text{Gamma}(135, 9.8) \\\\\n\\end{array}$$\n\n## Sparse Grid\n\nHere we will try this grid approximation idea over $N = 11$ values\n\n$$\\lambda \\in \\{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30\\}$$\n\n:::: {.panel-tabset}\n\n## Bayes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_counts <- c(18, 14, 23, 22, 12, 22, 7, 0, 1)\n\n# Step 1: Define a grid of 11 pi values\ngrid_data <- data.frame(lambda_grid = seq(from = 0, to = 30, \n                                      length = 11))\n\n# Step 2: Evaluate the prior & likelihood at each pi\ngrid_data <- grid_data %>% \n  mutate(prior = dgamma(lambda_grid, 16, 0.8),\n         likelihood = dpois(18, lambda_grid)*\n           dpois(14, lambda_grid)*\n           dpois(23, lambda_grid)*\n           dpois(22, lambda_grid)*\n           dpois(12, lambda_grid)*\n           dpois(22, lambda_grid)*\n           dpois(7, lambda_grid)*\n           dpois(0, lambda_grid)*\n           dpois(1, lambda_grid))\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n```\n:::\n\n\n## Grid Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(grid_data, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   lambda_grid  prior likelihood unnormalized posterior\n1            0 0.0000          0            0    0.0000\n2            3 0.0000          0            0    0.0000\n3            6 0.0001          0            0    0.0000\n4            9 0.0033          0            0    0.0000\n5           12 0.0225          0            0    0.3756\n6           15 0.0579          0            0    0.6200\n7           18 0.0809          0            0    0.0043\n8           21 0.0741          0            0    0.0000\n9           24 0.0498          0            0    0.0000\n10          27 0.0265          0            0    0.0000\n11          30 0.0117          0            0    0.0000\n```\n:::\n:::\n\n\n## Grid Values\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## Graph 1 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the grid approximated posterior\nggplot(grid_data, aes(x = lambda_grid, y = posterior)) + \n  geom_segment(aes(x = lambda_grid, xend = lambda_grid, y = 0, yend = posterior),\n               color = \"gray50\",\n               linewidth = 2) +\n  geom_point(size = 7) + \n  labs(title = \"Sparse Grid\",\n         subtitle = \"Gamma-Poisson Example\",\n         caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n## Posterior Sampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 4: sample from the discretized posterior\nposterior_sample <- sample_n(grid_data, \n                             size = 10000, \n                             weight = posterior, \n                             replace = TRUE)\n```\n:::\n\n\n## Alignment\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Graph 2 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(posterior_sample, aes(x = pi_grid)) + \n  geom_histogram(aes(y = after_stat(density)), \n                 binwidth = 0.1,\n                 fill = \"gray50\") + \n  stat_function(fun = dbeta, args = list(7, 8),\n                color = \"#E77500\", linewidth = 3) + \n  lims(x = c(0, 1)) +\n  labs(title = \"Sparse Grid: <span style='color:#7F7F7F'>simulation</span> versus <span style='color:#E77500'>theoretical</span>\",\n         subtitle = \"Gamma-Poisson Example\",\n         caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown())\n```\n:::\n\n\n::::\n\n\n## Dense Grid\n\nHere we will try this grid approximation idea over $N = 501$ values\n\n$$\\lambda \\in [0, 30]$$\n\n:::: {.panel-tabset}\n\n## Bayes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_counts <- c(18, 14, 23, 22, 12, 22, 7, 0, 1)\n\n# Step 1: Define a grid of 11 pi values\ngrid_data <- data.frame(lambda_grid = seq(from = 0, to = 30, \n                                      length = 501))\n\n# Step 2: Evaluate the prior & likelihood at each pi\ngrid_data <- grid_data %>% \n  mutate(prior = dgamma(lambda_grid, 16, 0.8),\n         likelihood = dpois(18, lambda_grid)*\n           dpois(14, lambda_grid)*\n           dpois(23, lambda_grid)*\n           dpois(22, lambda_grid)*\n           dpois(12, lambda_grid)*\n           dpois(22, lambda_grid)*\n           dpois(7, lambda_grid)*\n           dpois(0, lambda_grid)*\n           dpois(1, lambda_grid))\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n```\n:::\n\n\n## Grid Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(grid_data, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    lambda_grid  prior likelihood unnormalized posterior\n1          0.00 0.0000          0            0    0.0000\n2          0.06 0.0000          0            0    0.0000\n3          0.12 0.0000          0            0    0.0000\n4          0.18 0.0000          0            0    0.0000\n5          0.24 0.0000          0            0    0.0000\n6          0.30 0.0000          0            0    0.0000\n7          0.36 0.0000          0            0    0.0000\n8          0.42 0.0000          0            0    0.0000\n9          0.48 0.0000          0            0    0.0000\n10         0.54 0.0000          0            0    0.0000\n11         0.60 0.0000          0            0    0.0000\n12         0.66 0.0000          0            0    0.0000\n13         0.72 0.0000          0            0    0.0000\n14         0.78 0.0000          0            0    0.0000\n15         0.84 0.0000          0            0    0.0000\n16         0.90 0.0000          0            0    0.0000\n17         0.96 0.0000          0            0    0.0000\n18         1.02 0.0000          0            0    0.0000\n19         1.08 0.0000          0            0    0.0000\n20         1.14 0.0000          0            0    0.0000\n21         1.20 0.0000          0            0    0.0000\n22         1.26 0.0000          0            0    0.0000\n23         1.32 0.0000          0            0    0.0000\n24         1.38 0.0000          0            0    0.0000\n25         1.44 0.0000          0            0    0.0000\n26         1.50 0.0000          0            0    0.0000\n27         1.56 0.0000          0            0    0.0000\n28         1.62 0.0000          0            0    0.0000\n29         1.68 0.0000          0            0    0.0000\n30         1.74 0.0000          0            0    0.0000\n31         1.80 0.0000          0            0    0.0000\n32         1.86 0.0000          0            0    0.0000\n33         1.92 0.0000          0            0    0.0000\n34         1.98 0.0000          0            0    0.0000\n35         2.04 0.0000          0            0    0.0000\n36         2.10 0.0000          0            0    0.0000\n37         2.16 0.0000          0            0    0.0000\n38         2.22 0.0000          0            0    0.0000\n39         2.28 0.0000          0            0    0.0000\n40         2.34 0.0000          0            0    0.0000\n41         2.40 0.0000          0            0    0.0000\n42         2.46 0.0000          0            0    0.0000\n43         2.52 0.0000          0            0    0.0000\n44         2.58 0.0000          0            0    0.0000\n45         2.64 0.0000          0            0    0.0000\n46         2.70 0.0000          0            0    0.0000\n47         2.76 0.0000          0            0    0.0000\n48         2.82 0.0000          0            0    0.0000\n49         2.88 0.0000          0            0    0.0000\n50         2.94 0.0000          0            0    0.0000\n51         3.00 0.0000          0            0    0.0000\n52         3.06 0.0000          0            0    0.0000\n53         3.12 0.0000          0            0    0.0000\n54         3.18 0.0000          0            0    0.0000\n55         3.24 0.0000          0            0    0.0000\n56         3.30 0.0000          0            0    0.0000\n57         3.36 0.0000          0            0    0.0000\n58         3.42 0.0000          0            0    0.0000\n59         3.48 0.0000          0            0    0.0000\n60         3.54 0.0000          0            0    0.0000\n61         3.60 0.0000          0            0    0.0000\n62         3.66 0.0000          0            0    0.0000\n63         3.72 0.0000          0            0    0.0000\n64         3.78 0.0000          0            0    0.0000\n65         3.84 0.0000          0            0    0.0000\n66         3.90 0.0000          0            0    0.0000\n67         3.96 0.0000          0            0    0.0000\n68         4.02 0.0000          0            0    0.0000\n69         4.08 0.0000          0            0    0.0000\n70         4.14 0.0000          0            0    0.0000\n71         4.20 0.0000          0            0    0.0000\n72         4.26 0.0000          0            0    0.0000\n73         4.32 0.0000          0            0    0.0000\n74         4.38 0.0000          0            0    0.0000\n75         4.44 0.0000          0            0    0.0000\n76         4.50 0.0000          0            0    0.0000\n77         4.56 0.0000          0            0    0.0000\n78         4.62 0.0000          0            0    0.0000\n79         4.68 0.0000          0            0    0.0000\n80         4.74 0.0000          0            0    0.0000\n81         4.80 0.0000          0            0    0.0000\n82         4.86 0.0000          0            0    0.0000\n83         4.92 0.0000          0            0    0.0000\n84         4.98 0.0000          0            0    0.0000\n85         5.04 0.0000          0            0    0.0000\n86         5.10 0.0000          0            0    0.0000\n87         5.16 0.0000          0            0    0.0000\n88         5.22 0.0000          0            0    0.0000\n89         5.28 0.0000          0            0    0.0000\n90         5.34 0.0000          0            0    0.0000\n91         5.40 0.0000          0            0    0.0000\n92         5.46 0.0000          0            0    0.0000\n93         5.52 0.0000          0            0    0.0000\n94         5.58 0.0000          0            0    0.0000\n95         5.64 0.0000          0            0    0.0000\n96         5.70 0.0000          0            0    0.0000\n97         5.76 0.0001          0            0    0.0000\n98         5.82 0.0001          0            0    0.0000\n99         5.88 0.0001          0            0    0.0000\n100        5.94 0.0001          0            0    0.0000\n101        6.00 0.0001          0            0    0.0000\n102        6.06 0.0001          0            0    0.0000\n103        6.12 0.0001          0            0    0.0000\n104        6.18 0.0001          0            0    0.0000\n105        6.24 0.0001          0            0    0.0000\n106        6.30 0.0001          0            0    0.0000\n107        6.36 0.0001          0            0    0.0000\n108        6.42 0.0002          0            0    0.0000\n109        6.48 0.0002          0            0    0.0000\n110        6.54 0.0002          0            0    0.0000\n111        6.60 0.0002          0            0    0.0000\n112        6.66 0.0002          0            0    0.0000\n113        6.72 0.0003          0            0    0.0000\n114        6.78 0.0003          0            0    0.0000\n115        6.84 0.0003          0            0    0.0000\n116        6.90 0.0003          0            0    0.0000\n117        6.96 0.0004          0            0    0.0000\n118        7.02 0.0004          0            0    0.0000\n119        7.08 0.0004          0            0    0.0000\n120        7.14 0.0005          0            0    0.0000\n121        7.20 0.0005          0            0    0.0000\n122        7.26 0.0005          0            0    0.0000\n123        7.32 0.0006          0            0    0.0000\n124        7.38 0.0006          0            0    0.0000\n125        7.44 0.0007          0            0    0.0000\n126        7.50 0.0007          0            0    0.0000\n127        7.56 0.0008          0            0    0.0000\n128        7.62 0.0008          0            0    0.0000\n129        7.68 0.0009          0            0    0.0000\n130        7.74 0.0009          0            0    0.0000\n131        7.80 0.0010          0            0    0.0000\n132        7.86 0.0011          0            0    0.0000\n133        7.92 0.0012          0            0    0.0000\n134        7.98 0.0012          0            0    0.0000\n135        8.04 0.0013          0            0    0.0000\n136        8.10 0.0014          0            0    0.0000\n137        8.16 0.0015          0            0    0.0000\n138        8.22 0.0016          0            0    0.0000\n139        8.28 0.0017          0            0    0.0000\n140        8.34 0.0018          0            0    0.0000\n141        8.40 0.0019          0            0    0.0000\n142        8.46 0.0020          0            0    0.0000\n143        8.52 0.0021          0            0    0.0000\n144        8.58 0.0023          0            0    0.0000\n145        8.64 0.0024          0            0    0.0000\n146        8.70 0.0025          0            0    0.0000\n147        8.76 0.0027          0            0    0.0000\n148        8.82 0.0028          0            0    0.0000\n149        8.88 0.0030          0            0    0.0000\n150        8.94 0.0031          0            0    0.0000\n151        9.00 0.0033          0            0    0.0000\n152        9.06 0.0035          0            0    0.0000\n153        9.12 0.0037          0            0    0.0000\n154        9.18 0.0039          0            0    0.0000\n155        9.24 0.0041          0            0    0.0000\n156        9.30 0.0043          0            0    0.0000\n157        9.36 0.0045          0            0    0.0000\n158        9.42 0.0047          0            0    0.0000\n159        9.48 0.0049          0            0    0.0000\n160        9.54 0.0051          0            0    0.0000\n161        9.60 0.0054          0            0    0.0000\n162        9.66 0.0056          0            0    0.0000\n163        9.72 0.0059          0            0    0.0000\n164        9.78 0.0062          0            0    0.0000\n165        9.84 0.0064          0            0    0.0000\n166        9.90 0.0067          0            0    0.0000\n167        9.96 0.0070          0            0    0.0000\n168       10.02 0.0073          0            0    0.0001\n169       10.08 0.0076          0            0    0.0001\n170       10.14 0.0080          0            0    0.0001\n171       10.20 0.0083          0            0    0.0001\n172       10.26 0.0086          0            0    0.0001\n173       10.32 0.0090          0            0    0.0002\n174       10.38 0.0093          0            0    0.0002\n175       10.44 0.0097          0            0    0.0002\n176       10.50 0.0101          0            0    0.0003\n177       10.56 0.0104          0            0    0.0003\n178       10.62 0.0108          0            0    0.0004\n179       10.68 0.0112          0            0    0.0005\n180       10.74 0.0117          0            0    0.0005\n181       10.80 0.0121          0            0    0.0006\n182       10.86 0.0125          0            0    0.0007\n183       10.92 0.0130          0            0    0.0009\n184       10.98 0.0134          0            0    0.0010\n185       11.04 0.0139          0            0    0.0012\n186       11.10 0.0143          0            0    0.0013\n187       11.16 0.0148          0            0    0.0015\n188       11.22 0.0153          0            0    0.0017\n189       11.28 0.0158          0            0    0.0020\n190       11.34 0.0163          0            0    0.0022\n191       11.40 0.0168          0            0    0.0025\n192       11.46 0.0173          0            0    0.0028\n193       11.52 0.0179          0            0    0.0032\n194       11.58 0.0184          0            0    0.0035\n195       11.64 0.0190          0            0    0.0039\n196       11.70 0.0195          0            0    0.0043\n197       11.76 0.0201          0            0    0.0048\n198       11.82 0.0207          0            0    0.0052\n199       11.88 0.0213          0            0    0.0057\n200       11.94 0.0219          0            0    0.0062\n201       12.00 0.0225          0            0    0.0068\n202       12.06 0.0231          0            0    0.0074\n203       12.12 0.0237          0            0    0.0079\n204       12.18 0.0243          0            0    0.0085\n205       12.24 0.0249          0            0    0.0092\n206       12.30 0.0256          0            0    0.0098\n207       12.36 0.0262          0            0    0.0105\n208       12.42 0.0269          0            0    0.0111\n209       12.48 0.0276          0            0    0.0118\n210       12.54 0.0282          0            0    0.0124\n211       12.60 0.0289          0            0    0.0131\n212       12.66 0.0296          0            0    0.0137\n213       12.72 0.0303          0            0    0.0144\n214       12.78 0.0310          0            0    0.0150\n215       12.84 0.0316          0            0    0.0156\n216       12.90 0.0323          0            0    0.0162\n217       12.96 0.0331          0            0    0.0168\n218       13.02 0.0338          0            0    0.0173\n219       13.08 0.0345          0            0    0.0178\n220       13.14 0.0352          0            0    0.0182\n221       13.20 0.0359          0            0    0.0187\n222       13.26 0.0367          0            0    0.0190\n223       13.32 0.0374          0            0    0.0193\n224       13.38 0.0381          0            0    0.0196\n225       13.44 0.0389          0            0    0.0199\n226       13.50 0.0396          0            0    0.0200\n227       13.56 0.0403          0            0    0.0202\n228       13.62 0.0411          0            0    0.0202\n229       13.68 0.0418          0            0    0.0203\n230       13.74 0.0426          0            0    0.0202\n231       13.80 0.0433          0            0    0.0201\n232       13.86 0.0440          0            0    0.0200\n233       13.92 0.0448          0            0    0.0198\n234       13.98 0.0455          0            0    0.0196\n235       14.04 0.0463          0            0    0.0193\n236       14.10 0.0470          0            0    0.0190\n237       14.16 0.0478          0            0    0.0186\n238       14.22 0.0485          0            0    0.0182\n239       14.28 0.0493          0            0    0.0178\n240       14.34 0.0500          0            0    0.0174\n241       14.40 0.0507          0            0    0.0169\n242       14.46 0.0515          0            0    0.0164\n243       14.52 0.0522          0            0    0.0158\n244       14.58 0.0529          0            0    0.0153\n245       14.64 0.0537          0            0    0.0147\n246       14.70 0.0544          0            0    0.0141\n247       14.76 0.0551          0            0    0.0135\n248       14.82 0.0558          0            0    0.0130\n249       14.88 0.0565          0            0    0.0124\n250       14.94 0.0572          0            0    0.0118\n251       15.00 0.0579          0            0    0.0112\n252       15.06 0.0586          0            0    0.0106\n253       15.12 0.0593          0            0    0.0100\n254       15.18 0.0600          0            0    0.0095\n255       15.24 0.0606          0            0    0.0089\n256       15.30 0.0613          0            0    0.0084\n257       15.36 0.0620          0            0    0.0079\n258       15.42 0.0626          0            0    0.0074\n259       15.48 0.0633          0            0    0.0069\n260       15.54 0.0639          0            0    0.0064\n261       15.60 0.0645          0            0    0.0060\n262       15.66 0.0652          0            0    0.0056\n263       15.72 0.0658          0            0    0.0052\n264       15.78 0.0664          0            0    0.0048\n265       15.84 0.0670          0            0    0.0044\n266       15.90 0.0676          0            0    0.0041\n267       15.96 0.0681          0            0    0.0037\n268       16.02 0.0687          0            0    0.0034\n269       16.08 0.0693          0            0    0.0032\n270       16.14 0.0698          0            0    0.0029\n271       16.20 0.0703          0            0    0.0026\n272       16.26 0.0709          0            0    0.0024\n273       16.32 0.0714          0            0    0.0022\n274       16.38 0.0719          0            0    0.0020\n275       16.44 0.0724          0            0    0.0018\n276       16.50 0.0729          0            0    0.0016\n277       16.56 0.0733          0            0    0.0015\n278       16.62 0.0738          0            0    0.0013\n279       16.68 0.0742          0            0    0.0012\n280       16.74 0.0747          0            0    0.0011\n281       16.80 0.0751          0            0    0.0010\n282       16.86 0.0755          0            0    0.0009\n283       16.92 0.0759          0            0    0.0008\n284       16.98 0.0763          0            0    0.0007\n285       17.04 0.0767          0            0    0.0006\n286       17.10 0.0770          0            0    0.0005\n287       17.16 0.0774          0            0    0.0005\n288       17.22 0.0777          0            0    0.0004\n289       17.28 0.0781          0            0    0.0004\n290       17.34 0.0784          0            0    0.0003\n291       17.40 0.0787          0            0    0.0003\n292       17.46 0.0790          0            0    0.0003\n293       17.52 0.0792          0            0    0.0002\n294       17.58 0.0795          0            0    0.0002\n295       17.64 0.0797          0            0    0.0002\n296       17.70 0.0800          0            0    0.0002\n297       17.76 0.0802          0            0    0.0001\n298       17.82 0.0804          0            0    0.0001\n299       17.88 0.0806          0            0    0.0001\n300       17.94 0.0808          0            0    0.0001\n301       18.00 0.0809          0            0    0.0001\n302       18.06 0.0811          0            0    0.0001\n303       18.12 0.0812          0            0    0.0001\n304       18.18 0.0814          0            0    0.0001\n305       18.24 0.0815          0            0    0.0000\n306       18.30 0.0816          0            0    0.0000\n307       18.36 0.0817          0            0    0.0000\n308       18.42 0.0818          0            0    0.0000\n309       18.48 0.0818          0            0    0.0000\n310       18.54 0.0819          0            0    0.0000\n311       18.60 0.0819          0            0    0.0000\n312       18.66 0.0819          0            0    0.0000\n313       18.72 0.0819          0            0    0.0000\n314       18.78 0.0819          0            0    0.0000\n315       18.84 0.0819          0            0    0.0000\n316       18.90 0.0819          0            0    0.0000\n317       18.96 0.0819          0            0    0.0000\n318       19.02 0.0818          0            0    0.0000\n319       19.08 0.0818          0            0    0.0000\n320       19.14 0.0817          0            0    0.0000\n321       19.20 0.0816          0            0    0.0000\n322       19.26 0.0815          0            0    0.0000\n323       19.32 0.0814          0            0    0.0000\n324       19.38 0.0813          0            0    0.0000\n325       19.44 0.0811          0            0    0.0000\n326       19.50 0.0810          0            0    0.0000\n327       19.56 0.0808          0            0    0.0000\n328       19.62 0.0807          0            0    0.0000\n329       19.68 0.0805          0            0    0.0000\n330       19.74 0.0803          0            0    0.0000\n331       19.80 0.0801          0            0    0.0000\n332       19.86 0.0799          0            0    0.0000\n333       19.92 0.0797          0            0    0.0000\n334       19.98 0.0795          0            0    0.0000\n335       20.04 0.0792          0            0    0.0000\n336       20.10 0.0790          0            0    0.0000\n337       20.16 0.0787          0            0    0.0000\n338       20.22 0.0784          0            0    0.0000\n339       20.28 0.0782          0            0    0.0000\n340       20.34 0.0779          0            0    0.0000\n341       20.40 0.0776          0            0    0.0000\n342       20.46 0.0773          0            0    0.0000\n343       20.52 0.0770          0            0    0.0000\n344       20.58 0.0766          0            0    0.0000\n345       20.64 0.0763          0            0    0.0000\n346       20.70 0.0760          0            0    0.0000\n347       20.76 0.0756          0            0    0.0000\n348       20.82 0.0753          0            0    0.0000\n349       20.88 0.0749          0            0    0.0000\n350       20.94 0.0745          0            0    0.0000\n351       21.00 0.0741          0            0    0.0000\n352       21.06 0.0738          0            0    0.0000\n353       21.12 0.0734          0            0    0.0000\n354       21.18 0.0730          0            0    0.0000\n355       21.24 0.0726          0            0    0.0000\n356       21.30 0.0722          0            0    0.0000\n357       21.36 0.0717          0            0    0.0000\n358       21.42 0.0713          0            0    0.0000\n359       21.48 0.0709          0            0    0.0000\n360       21.54 0.0704          0            0    0.0000\n361       21.60 0.0700          0            0    0.0000\n362       21.66 0.0696          0            0    0.0000\n363       21.72 0.0691          0            0    0.0000\n364       21.78 0.0687          0            0    0.0000\n365       21.84 0.0682          0            0    0.0000\n366       21.90 0.0677          0            0    0.0000\n367       21.96 0.0673          0            0    0.0000\n368       22.02 0.0668          0            0    0.0000\n369       22.08 0.0663          0            0    0.0000\n370       22.14 0.0658          0            0    0.0000\n371       22.20 0.0653          0            0    0.0000\n372       22.26 0.0648          0            0    0.0000\n373       22.32 0.0644          0            0    0.0000\n374       22.38 0.0639          0            0    0.0000\n375       22.44 0.0634          0            0    0.0000\n376       22.50 0.0629          0            0    0.0000\n377       22.56 0.0624          0            0    0.0000\n378       22.62 0.0618          0            0    0.0000\n379       22.68 0.0613          0            0    0.0000\n380       22.74 0.0608          0            0    0.0000\n381       22.80 0.0603          0            0    0.0000\n382       22.86 0.0598          0            0    0.0000\n383       22.92 0.0593          0            0    0.0000\n384       22.98 0.0588          0            0    0.0000\n385       23.04 0.0582          0            0    0.0000\n386       23.10 0.0577          0            0    0.0000\n387       23.16 0.0572          0            0    0.0000\n388       23.22 0.0567          0            0    0.0000\n389       23.28 0.0562          0            0    0.0000\n390       23.34 0.0556          0            0    0.0000\n391       23.40 0.0551          0            0    0.0000\n392       23.46 0.0546          0            0    0.0000\n393       23.52 0.0541          0            0    0.0000\n394       23.58 0.0535          0            0    0.0000\n395       23.64 0.0530          0            0    0.0000\n396       23.70 0.0525          0            0    0.0000\n397       23.76 0.0519          0            0    0.0000\n398       23.82 0.0514          0            0    0.0000\n399       23.88 0.0509          0            0    0.0000\n400       23.94 0.0504          0            0    0.0000\n401       24.00 0.0498          0            0    0.0000\n402       24.06 0.0493          0            0    0.0000\n403       24.12 0.0488          0            0    0.0000\n404       24.18 0.0483          0            0    0.0000\n405       24.24 0.0478          0            0    0.0000\n406       24.30 0.0472          0            0    0.0000\n407       24.36 0.0467          0            0    0.0000\n408       24.42 0.0462          0            0    0.0000\n409       24.48 0.0457          0            0    0.0000\n410       24.54 0.0452          0            0    0.0000\n411       24.60 0.0447          0            0    0.0000\n412       24.66 0.0442          0            0    0.0000\n413       24.72 0.0437          0            0    0.0000\n414       24.78 0.0432          0            0    0.0000\n415       24.84 0.0426          0            0    0.0000\n416       24.90 0.0421          0            0    0.0000\n417       24.96 0.0417          0            0    0.0000\n418       25.02 0.0412          0            0    0.0000\n419       25.08 0.0407          0            0    0.0000\n420       25.14 0.0402          0            0    0.0000\n421       25.20 0.0397          0            0    0.0000\n422       25.26 0.0392          0            0    0.0000\n423       25.32 0.0387          0            0    0.0000\n424       25.38 0.0382          0            0    0.0000\n425       25.44 0.0378          0            0    0.0000\n426       25.50 0.0373          0            0    0.0000\n427       25.56 0.0368          0            0    0.0000\n428       25.62 0.0363          0            0    0.0000\n429       25.68 0.0359          0            0    0.0000\n430       25.74 0.0354          0            0    0.0000\n431       25.80 0.0349          0            0    0.0000\n432       25.86 0.0345          0            0    0.0000\n433       25.92 0.0340          0            0    0.0000\n434       25.98 0.0336          0            0    0.0000\n435       26.04 0.0331          0            0    0.0000\n436       26.10 0.0327          0            0    0.0000\n437       26.16 0.0323          0            0    0.0000\n438       26.22 0.0318          0            0    0.0000\n439       26.28 0.0314          0            0    0.0000\n440       26.34 0.0310          0            0    0.0000\n441       26.40 0.0305          0            0    0.0000\n442       26.46 0.0301          0            0    0.0000\n443       26.52 0.0297          0            0    0.0000\n444       26.58 0.0293          0            0    0.0000\n445       26.64 0.0289          0            0    0.0000\n446       26.70 0.0284          0            0    0.0000\n447       26.76 0.0280          0            0    0.0000\n448       26.82 0.0276          0            0    0.0000\n449       26.88 0.0272          0            0    0.0000\n450       26.94 0.0269          0            0    0.0000\n451       27.00 0.0265          0            0    0.0000\n452       27.06 0.0261          0            0    0.0000\n453       27.12 0.0257          0            0    0.0000\n454       27.18 0.0253          0            0    0.0000\n455       27.24 0.0249          0            0    0.0000\n456       27.30 0.0246          0            0    0.0000\n457       27.36 0.0242          0            0    0.0000\n458       27.42 0.0238          0            0    0.0000\n459       27.48 0.0235          0            0    0.0000\n460       27.54 0.0231          0            0    0.0000\n461       27.60 0.0228          0            0    0.0000\n462       27.66 0.0224          0            0    0.0000\n463       27.72 0.0221          0            0    0.0000\n464       27.78 0.0217          0            0    0.0000\n465       27.84 0.0214          0            0    0.0000\n466       27.90 0.0211          0            0    0.0000\n467       27.96 0.0207          0            0    0.0000\n468       28.02 0.0204          0            0    0.0000\n469       28.08 0.0201          0            0    0.0000\n470       28.14 0.0198          0            0    0.0000\n471       28.20 0.0195          0            0    0.0000\n472       28.26 0.0191          0            0    0.0000\n473       28.32 0.0188          0            0    0.0000\n474       28.38 0.0185          0            0    0.0000\n475       28.44 0.0182          0            0    0.0000\n476       28.50 0.0179          0            0    0.0000\n477       28.56 0.0176          0            0    0.0000\n478       28.62 0.0174          0            0    0.0000\n479       28.68 0.0171          0            0    0.0000\n480       28.74 0.0168          0            0    0.0000\n481       28.80 0.0165          0            0    0.0000\n482       28.86 0.0162          0            0    0.0000\n483       28.92 0.0160          0            0    0.0000\n484       28.98 0.0157          0            0    0.0000\n485       29.04 0.0154          0            0    0.0000\n486       29.10 0.0152          0            0    0.0000\n487       29.16 0.0149          0            0    0.0000\n488       29.22 0.0147          0            0    0.0000\n489       29.28 0.0144          0            0    0.0000\n490       29.34 0.0142          0            0    0.0000\n491       29.40 0.0139          0            0    0.0000\n492       29.46 0.0137          0            0    0.0000\n493       29.52 0.0134          0            0    0.0000\n494       29.58 0.0132          0            0    0.0000\n495       29.64 0.0130          0            0    0.0000\n496       29.70 0.0127          0            0    0.0000\n497       29.76 0.0125          0            0    0.0000\n498       29.82 0.0123          0            0    0.0000\n499       29.88 0.0121          0            0    0.0000\n500       29.94 0.0119          0            0    0.0000\n501       30.00 0.0117          0            0    0.0000\n```\n:::\n:::\n\n\n## Grid Values\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n## Graph 1 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the grid approximated posterior\nggplot(grid_data, aes(x = lambda_grid, y = posterior)) + \n  geom_segment(aes(x = lambda_grid, xend = lambda_grid, y = 0, yend = posterior),\n               color = \"gray50\",\n               linewidth = 1) +\n  geom_point(size = 2) + \n  labs(title = \"Dense Grid\",\n         subtitle = \"Gamma-Poisson Example\",\n         caption = \"SML 320\") +\n  theme_minimal()\n```\n:::\n\n\n## Posterior Sampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 4: sample from the discretized posterior\nposterior_sample <- sample_n(grid_data, \n                             size = 10000, \n                             weight = posterior, \n                             replace = TRUE)\n```\n:::\n\n\n## Alignment\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n## Graph 2 Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(posterior_sample, aes(x = pi_grid)) + \n  geom_histogram(aes(y = after_stat(density)), \n                 binwidth = 0.5,\n                 color = \"black\",\n                 fill = \"gray50\") + \n  stat_function(fun = dgamma, args = list(135, 9.8),\n                color = \"#E77500\", linewidth = 3) + \n  lims(x = c(0, 1)) +\n  labs(title = \"Dense Grid: <span style='color:#7F7F7F'>simulation</span> versus <span style='color:#E77500'>theoretical</span>\",\n         subtitle = \"Gamma-Poisson Example\",\n         caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown())\n```\n:::\n\n\n::::\n\n## Limitations\n\n* Handling larger data sets\n* Handling multiple parameters\n\n$$\\vec{\\theta} = (\\theta_{1}, \\theta_{2}, ..., \\theta_{k})$$\n\n* [Curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality): As the number of variables increases, \"the volume of the space increases so fast that the available data become sparse. In order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality\" --- Wikipedia\n\n    * Beta-Binomial example: $N = 101$ grid points\n    * Gamma-Poisson example: $N = 501$ grid points\n\n\n# MCMC\n\n## Andrey Markov\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n* 1868 - 1908\n* Russian Mathematician\n* known for stochastic processes\n* thesis supervisor of Georgy Voronoi\n:::\n\n::: {.column width=\"40%\"}\n![Andrey Markov](Andrey_Markov.png)\n:::\n\n::::\n\n## Stanislaw Ulam\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n* 1909 - 1984\n* Polish Mathematician\n* known for Monte Carlo methods\n* indefinite appointment at [IAS](https://www.ias.edu/ideas/adventures-mathematician)\n:::\n\n::: {.column width=\"40%\"}\n![John von Neumann, Richard Feynman, and Stanislaw Ulam, at Bandelier National Monument near Los Alamos, 1949 ](Neumann_Feynman_Ulam.png)\n\n* image source: Institute for Advanced Study\n:::\n\n::::\n\n## MCMC Chains\n\nLet $\\{ \\theta^{(1)}, \\theta^{(2)}, ..., \\theta^{(N)} \\}$ be an **MCMC chain (Markov Chain Monte Carlo)**.\n\n* **Markov Property**:\n\n$$f\\left( \\theta^{(i+1)} \\bigg| \\theta^{(1)}, \\theta^{(2)}, ..., \\theta^{(i)}, y \\right) = f\\left( \\theta^{(i+1)} \\bigg| \\theta^{(i)}, y \\right)$$\n\n* MCMC simulation produces a chain of $N$ dependent values\n* These values are not drawn from the posterior pdf $f(\\theta|y)$\n\n## Stan\n\n## Example: Beta-Binomial\n\n### Scenario: Smokers in Restaurants\n\nLet us start with a vague beta prior, use a binomial model to get the likelihood of $y = 4$ smokers among $n = 9$ customers, and then get a beta posterior.\n\n$$\\begin{array}{rrcl}\n  \\text{prior: } & \\pi & \\sim & \\text{Beta}(3, 3) \\\\\n  \\text{likelihood: } & Y|\\pi & \\sim & \\text{Bin}(9, \\pi) \\\\\n  \\text{posterior: } & \\pi|Y & \\sim & \\text{Beta}(7, 8) \\\\\n\\end{array}$$\n\n:::: {.panel-tabset}\n\n## Define Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# STEP 1: DEFINE the model\nbb_model <- \"\n  data {\n    int<lower = 0, upper = 9> Y;\n  }\n  parameters {\n    real<lower = 0, upper = 1> pi;\n  }\n  model {\n    Y ~ binomial(9, pi);\n    pi ~ beta(2, 2);\n  }\n\"\n```\n:::\n\n\n## Simulate Posterior\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\n\n# STEP 2: SIMULATE the posterior\nbb_sim <- stan(model_code = bb_model, data = list(Y = 4), \n               chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.028 seconds (Warm-up)\nChain 1:                0.029 seconds (Sampling)\nChain 1:                0.057 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.028 seconds (Warm-up)\nChain 2:                0.03 seconds (Sampling)\nChain 2:                0.058 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.027 seconds (Warm-up)\nChain 3:                0.029 seconds (Sampling)\nChain 3:                0.056 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 9e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.027 seconds (Warm-up)\nChain 4:                0.029 seconds (Sampling)\nChain 4:                0.056 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nend_time <- Sys.time()\nprint(round(end_time- start_time))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 38 secs\n```\n:::\n:::\n\n\n## Histogram\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(bb_sim, pars = \"pi\")\n```\n\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n## Density\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_dens(bb_sim, pars = \"pi\") + \n  stat_function(fun = dbeta, args = list(7, 8),\n                color = \"#E77500\", linewidth = 3) + \n  labs(title = \"MCMC: <span style='color:#619CFF'>simulation</span> versus <span style='color:#E77500'>theoretical</span>\",\n         subtitle = \"Beta-Binomial Example\",\n         caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown())\n```\n\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n::::\n\n\n## Example: Gamma-Poisson \n\n### Scenario: Drug Law Violations\n\nLet us start with a vague Gamma prior, use a binomial model to get the likelihood of $\\sum y = 119$ drug law violations over $n = 9$ years, and then get a Gamma posterior.\n\n$$\\begin{array}{rrcl}\n  \\text{prior: } & \\pi & \\sim & \\text{Gamma}(16, 0.8) \\\\\n  \\text{likelihood: } & Y|\\pi & \\sim & \\text{Pois}(119/9) \\\\\n  \\text{posterior: } & \\pi|Y & \\sim & \\text{Gamma}(135, 9.8) \\\\\n\\end{array}$$\n\n:::: {.panel-tabset}\n\n## Define Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# STEP 1: DEFINE the model\ngp_model <- \"\n  data {\n    int<lower = 0> Y[9];\n  }\n  parameters {\n    real<lower = 0> lambda;\n  }\n  model {\n    Y ~ poisson(lambda);\n    lambda ~ gamma(16, 0.8);\n  }\n\"\n```\n:::\n\n\n## Simulate Posterior\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\n\n# STEP 2: SIMULATE the posterior\nobs_counts <- c(18, 14, 23, 22, 12, 22, 7, 0, 1)\ngp_sim <- stan(model_code = gp_model, \n               data = list(Y = obs_counts), \n               chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.031 seconds (Warm-up)\nChain 1:                0.032 seconds (Sampling)\nChain 1:                0.063 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.038 seconds (Warm-up)\nChain 2:                0.028 seconds (Sampling)\nChain 2:                0.066 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.032 seconds (Warm-up)\nChain 3:                0.034 seconds (Sampling)\nChain 3:                0.066 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 3e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.034 seconds (Warm-up)\nChain 4:                0.028 seconds (Sampling)\nChain 4:                0.062 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nend_time <- Sys.time()\nprint(round(end_time- start_time))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 38 secs\n```\n:::\n:::\n\n\n## Histogram\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(gp_sim, pars = \"lambda\")\n```\n\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n## Density\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_dens(gp_sim, pars = \"lambda\") + \n  stat_function(fun = dgamma, args = list(135, 9.8),\n                color = \"#E77500\", linewidth = 3) + \n  labs(title = \"MCMC: <span style='color:#619CFF'>simulation</span> versus <span style='color:#E77500'>theoretical</span>\",\n         subtitle = \"Gamma-Poisson Example\",\n         caption = \"SML 320\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown())\n```\n\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n::::\n\n# Quo Vadimus\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Trace plots of the 4 Markov chains\nmcmc_trace(gp_sim, pars = \"lambda\", size = 0.1)\n```\n\n::: {.cell-output-display}\n![](06_approx_posterior_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n* How do we know if the MCMC calculations are complete?\n* How do we know if the MCMC calculations are reliable?\n* How does MCMC work in approximating the posterior distribution?\n\n# Footnotes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.0 (2023-04-21 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0      dplyr_1.1.3       \n [5] purrr_1.0.2        readr_2.1.4        tidyr_1.3.0        tibble_3.2.1      \n [9] ggplot2_3.4.3      tidyverse_2.0.0    rstan_2.32.5       StanHeaders_2.32.5\n[13] ggtext_0.1.2       bayesplot_1.10.0  \n\nloaded via a namespace (and not attached):\n [1] tensorA_0.36.2       gtable_0.3.4         xfun_0.40           \n [4] QuickJSR_1.1.3       htmlwidgets_1.6.2    processx_3.8.1      \n [7] inline_0.3.19        callr_3.7.3          tzdb_0.4.0          \n[10] vctrs_0.6.3          tools_4.3.0          ps_1.7.5            \n[13] generics_0.1.3       stats4_4.3.0         curl_5.0.2          \n[16] parallel_4.3.0       fansi_1.0.4          pkgconfig_2.0.3     \n[19] checkmate_2.2.0      distributional_0.3.2 RcppParallel_5.1.7  \n[22] lifecycle_1.0.4      compiler_4.3.0       farver_2.1.1        \n[25] munsell_0.5.0        codetools_0.2-19     htmltools_0.5.6     \n[28] yaml_2.3.7           pillar_1.9.0         crayon_1.5.2        \n[31] abind_1.4-5          posterior_1.4.1      commonmark_1.9.0    \n[34] tidyselect_1.2.0     digest_0.6.33        stringi_1.7.12      \n[37] reshape2_1.4.4       labeling_0.4.3       fastmap_1.1.1       \n[40] grid_4.3.0           colorspace_2.1-0     cli_3.6.1           \n[43] magrittr_2.0.3       loo_2.6.0            pkgbuild_1.4.0      \n[46] utf8_1.2.3           withr_2.5.2          backports_1.4.1     \n[49] prettyunits_1.1.1    scales_1.2.1         timechange_0.2.0    \n[52] rmarkdown_2.24       matrixStats_1.0.0    gridExtra_2.3       \n[55] hms_1.1.3            evaluate_0.21        knitr_1.43          \n[58] V8_4.3.0             markdown_1.8         rlang_1.1.1         \n[61] gridtext_0.1.5       Rcpp_1.0.11          glue_1.6.2          \n[64] xml2_1.3.5           rstudioapi_0.15.0    jsonlite_1.8.7      \n[67] plyr_1.8.8           R6_2.5.1            \n```\n:::\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\n:::\n\n::::\n\n:::: {.panel-tabset}\n\n\n\n::::",
    "supporting": [
      "06_approx_posterior_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}