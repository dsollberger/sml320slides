---
title: "1: Conditional Probability"
author: "Derek Sollberger"
date: "2024-01-30"
# format: 
#   revealjs:
#     scrollable: true
format: 
  html:
    toc: true
---

```{r}
#| echo: false
#| message: false
#| warning: false
library("gt")
library("tidyverse")
```

# SML 320

## Bayesian Analysis

* Spring 2024
* TuTh, 11 AM to 1220 PM
* Bendheim House 103
* Lecturer: Derek

    - I go by "Derek" or "teacher"

::: {.callout-tip collapse="true"}
## Course Description

This course provides an introduction to Bayesian analysis---a powerful statistical framework for making inferences and modeling uncertainty in a wide range of applications. Students will explore the fundamental principles of Bayesian statistics, probability theory, Bayesian inference, and practical applications of Bayesian modeling. The course will cover both the theory and hands-on implementation using data science software and the R programming language.
:::

# Introducting the Presenter

## Lecturer

![](Lecturer_Derek.png)


## Current Research in Pedagogy

:::: {.columns}

::: {.column width="50%"}
![](MBVP SABER poster.png)
:::

::: {.column width="50%"}
- active learning
- computer programming
- flipped classrooms
:::

::::

## Identity Statement

:::: {.columns}

::: {.column width="75%"}
- Originally from Los Angeles
- Math: easier to understand through graphs
- Computer Programming: years of experience with R, Python, MATLAB, PHP, HTML, etc.
- Learning: drawn to puzzles and manageable tasks
- Personality: shy, introvert
:::

::: {.column width="25%"}
![](math-zach-galifianakis.gif)
:::

::::


# Icebreaker

* name
* major (and minors or certificates if applicable)
* unusual goal

    - (please pick a goal other than "get good grades")
    - whatever time frame makes sense
    
::: {.callout-tip collapse="true"}
## Derek's Example

"Hi.  My name is Derek, and I majored in applied mathematics.  My unusual goal is, for this upcoming year, to eat at that sushi place in Philadelphia that requires reservations a month in advance."
:::


# Assessment

::: {.callout-note collapse="true"}

## Before Lecture

* 10 percent of semester grade
* review or preview of statistics ideas, definitions, etc.
* must be completed before class
* may be repeated until correct

:::

::: {.callout-note collapse="true"}

## Computation

* 25 percent of semester grade
* weekly problem sets from textbook or instructor
* students are encouraged to discuss these tasks during precepts and study groups

:::

::: {.callout-note collapse="true"}

## Inference

* 15 percent of semester grade
* Students will be presented scenarios of model summaries and results and will be asked to answer inference tasks.
* These assignments will be handled through GradeScope.

:::

::: {.callout-warning collapse="true"}

## Project Benchmarks

* 10 percent of semester grade
* As seen in the schedule below, students will maintain progress toward their semester project.
* Students are encouraged to discuss these plans during precepts and office hours.

:::

::: {.callout-warning collapse="true"}

## Progress Presentation

* 10 percent of semester grade
* Students will update instructors and their peers on their data search, exploratory data analysis, and statistical modeling

:::

::: {.callout-important collapse="true"}

## Final Presentation

* 10 percent of semester grade
* Students will present their application of Bayesian techniques and literature review toward their semester project

:::

::: {.callout-important collapse="true"}

## Semester Project

* 20 percent of semester grade
* The culminating semester project will be due at the end of the semester examination period and will be assessed according to a rubric that will be provided in advance.

:::


# Probability

## Classical Probability

::: {.panel-tabset}

## Definition

$$P(A) = \frac{\text{number of outcomes that are } A}{\text{number of outcomes total}}$$

## Example

**Overly simplistic example**

It snowed during 2 of the 30 days of January in 2024.  We can claim that it snows $\frac{2}{30}$ of the days in Princeton.

:::

## Frequentist Probablity

::: {.panel-tabset}

## Definition

$$P(A) = \lim_{n \to \infty} \frac{\text{number of outcomes that are } A}{\text{number of outcomes total}}$$

## Example

**Overly simplistic example**

If we can model many months of weather in Princeton, we expect it to snow in about 3 percent of the days.

:::

## Bayesian Probability

::: {.panel-tabset}

## Definition

* prior belief: $P(A)$
* updated belief: $P(A|B)$

## Example

**Overly simplistic example**

It snowed during 2 of the 30 days of January in 2024.  Could we update our probability calculations for snow?

:::


# Reading List

## Textbook

:::: {.columns}

::: {.column width="60%"}
This course will closely follow the *Bayes Rules!* textbook by Alicia A Johnson, Miles Q Ott, and Mine Dogucu.  It is, in my opinion, the best blend of Bayesian thought, mathematical background, computer processes, and relevant applications.  The authors have made the materials of their textbook available online at <https://www.bayesrulesbook.com/>
:::

::: {.column width="40%"}
![Bayes Rules](Bayes_Rules_textbook_cover.png)
:::

::::

## Additional Reading

The following list of books is optional for student studies, but the instructor may use some materials to add depth and interest to the course.

::: {.callout-tip collapse="true"}

## Additional Reading

* *Statistical Rethinking* by Richard McElreath is the premier body of work in the field of Bayesian analysis.  This resource is great for people who want to build a strong foundation in philosophy and theory in this branch of mathematics.
* *Bayesian Data Analysis* by Andrew Gelman, et al., is the classic textbook (available online) in this field that is used in several university courses.  The authors' approach work well for people looking to quickly add Bayesian approaches to their research skills.
* *Bayesian Statistics the Fun Way* by Will Kurt brings Bayesian notions to a broad audience and its presentation blends will with an introductory course in statistics.
* *Bayesian Thinking in Biostatistics* by Gary L Rosner, et al., provides rigorous applications in bioinformatics along with strong software use.

:::



# Administrative

::: {.callout-warning collapse="true"}

## Prerequisites

* Basic knowledge of probability distributions (binomial, normal)
* Understanding of statistical concepts (sampling, confidence intervals)
* Familiarity with R or Python programming is assumed
* One semester of Calculus or instructor approval

:::

::: {.callout-note collapse="true"}

## Course Learning Outcomes

By the end of this course, students will be able to:

* Understand the foundational principles of Bayesian analysis and probability theory
* Apply Bayesian techniques for parameter estimation and regression models
* Create and interpret Bayesian models for various types of data
* Effectively communicate results and conclusions from Bayesian analyses
* Gain practical experience using Bayesian analysis software

:::

::: {.callout-note collapse="true"}

## Lecture Sessions

Please keep extra noise to a minimum.  Cell phones may be used as long as they are on silent or vibrate.  Please also review the Cooperative Classroom statement below.

:::

::: {.callout-note collapse="true"}

## Precepts

Precepts will be held for 80 minutes per week.  Students will develop problem-solving skills through collaborative work on the computer programming and written assignments while also working toward their semester projects.

:::

::: {.callout-note collapse="true"}

## Computers

Use of a laptop computer is highly recommended for this course, and students are asked to bring their laptop computer to every lecture and precept session.

* More information about computer needs can be found at <https://princeton.service-now.com/service?id=kb_article&sys_id=KB0013768>
* While Chromebooks (or other systems that discourage installation of software) can access cloud software, intensive calculations in this course may merit the use of a personal computer and downloaded software rather than server access.

:::

::: {.callout-tip collapse="true"}

## Special Accommodations

Students must register with the Office of Disability Services (ODS) (ods@princeton.edu; 258-8840) for disability verification and determination of eligibility for reasonable academic accommodations. Requests for academic accommodations for this course need to be made at the beginning of the semester, or as soon as possible for newly approved students, and again at least two weeks in advance of any needed accommodations in order to make arrangements to implement the accommodations. Please make an appointment to meet with me in order to maintain confidentiality in addressing your needs. No accommodations will be given without authorization from ODS, or without advance notice.

:::

::: {.callout-important collapse="true"}

## Academic Integrity Policy 

You are allowed to read text books and resources online. You may not ask other individuals questions (e.g., you may not ask questions on Stack Exchange or R help discussion groups). In accordance with the honor code, you must cite all sources of external information used in your work. This can be a book or a web site. Part of being a successful data scientist is having the ability to leverage existing information and techniques, so it is okay to do so in this course as long as you cite the reference.  University policies can be reviewed at <https://ua.princeton.edu/policies-resources/undergraduate-honor-system>

:::

# Learning Environment

## Cooperative Classroom

Learning in a cooperative environment should be stimulating, demanding, and fair.  Because this approach to learning is different from the competitive classroom structure that many other courses used to be based on, it is important for us to be clear about mutual expectations.  Below are my expectations for students in this class.  This set of expectations is intended to maximize debate and exchange of ideas in an atmosphere of mutual respect while preserving individual ownership of ideas and written words.  If you feel you do not understand or cannot agree to these expectations, you should discuss this with your instructor and classmates.

1.	Students are expected to work cooperatively with other members of the class and show respect for the ideas and contributions of other people.
2.	When working as part of a group, students should strive to be good contributors to the group, listen to others, not dominate, and recognize the contributions of others.  Students should try to ensure that everyone in the group is welcome to contribute and recognize that everyone contributes in different ways to a group process.
3.	Students should explore data, make observations, and develop inferences as part of a group.  If you use material from published sources, you must provide appropriate attribution.

:::: {.columns}

::: {.column width="50%"}
(Students will be asked to acknowledge this document in an online form.)

This document has been adapted from
*Scientific Teaching*
by Jo Handelsman, Sarah Miller, and Christine Pfund
:::

::: {.column width="50%"}
![Scientific Teaching](Scientific_Teaching.png)
:::

::::

## Pep Talk

Learning R can be difficult at first---it is like learning a new language, just like Spanish, French, or
Chinese. Hadley Wickham---the chief data scientist at RStudio and the author of some amazing R packages you will be using like `ggplot2`---made this wise observation:

::: {.callout-tip collapse="true"}

## Wisdom from Hadley Wickham

It's easy when you start out programming to get really frustrated and think, “Oh it's me, I'm really stupid,” or, “I'm not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It's just a natural part of programming. So, it happens to everyone and gets less and less over time. Don't blame yourself. Just take a break, do something fun, and then come back and try again later.

:::

If you are finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, ask questions ... e-mail [Derek], etc.  I promise you can do this.

---Andrew Heiss, Georgia State University   

## Inclusion Statement

I value all students regardless of their background, country of origin, race, religion, ethnicity, gender, sexual orientation, disability status, etc. and am committed to providing a climate of excellence and inclusiveness within all aspects of the course. If there are aspects of your culture or identity that you would like to share with me as they relate to your success in this class, I am happy to meet to discuss. Likewise, if you have any concerns in this area or facing any special issues or challenges, you are encouraged to discuss the matter with me (set up a meeting by e-mail) with an assurance of full confidentiality (only exception being mandatory reporting of academic integrity code violations or sexual harassment).


# Conditional Probability

## Setting

:::: {.columns}

::: {.column width="60%"}
Let us visit the lands of Faer&ucirc;n.  To grossly simplify and introduce notions from Dungeons and Dragons, let us define the following random variables:

* $H$: human
* $E$: evil

so that $H^{c}$ is "non-human" and $E^c$ is "not evil".
:::

::: {.column width="40%"}
![Baldur's Gate 3](bg3.png)
:::

::::

::: {.callout-tip collapse="true"}

## Unicode Characters

Derek wanted to make a note to himself here that the way to make accented letters in a markdown environment is to use [unicode characters](https://en.wikipedia.org/wiki/List_of_Unicode_characters).

:::

## Example

::: {.panel-tabset}

## Contingency Table

```{r}
#| echo: false
#| eval: true

alignment <- c("evil", "not evil")
human <- c("24", "30")
non_human <- c("88", "178")

bg3_df <- data.frame(alignment, human, non_human)

bg3_gt_table <- bg3_df |>
  gt(rowname_col = "alignment") |>
  cols_align(align = "right", columns = alignment) |>
  cols_align(align = "center",  columns = c(human, non_human)) |>
  tab_style(locations = cells_body(columns = c(human, non_human)),
            style = list(cell_fill(color = "yellow")))

bg3_gt_table #display table
```

Compute $P(E^{c}|H)$ and $P(H^{c}|E)$

## Code

```{r}
#| echo: true
#| eval: false

alignment <- c("evil", "not evil")
human <- c("24", "30")
non_human <- c("88", "178")

bg3_df <- data.frame(alignment, human, non_human)

bg3_gt_table <- bg3_df |>
  gt(rowname_col = "alignment") |>
  cols_align(align = "right", columns = alignment) |>
  cols_align(align = "center",  columns = c(human, non_human)) |>
  tab_style(locations = cells_body(columns = c(human, non_human)),
            style = list(cell_fill(color = "yellow")))

bg3_gt_table #display table
```

:::

## Practice

```{r}
#| echo: false
#| eval: true

bg3_gt_table #display table
```

Compute $P(H|E)$ and $P(E|H)$.  What do you observe about the results?


# Metrics

## Setting

:::: {.columns}

::: {.column width="60%"}
During the Winter of 2024, Kaggle had a [competition](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/overview) where programmers were asked to "create an energy prediction model of prosumers to reduce energy imbalance costs" based on data that included property information, historical weather, and forecasted weather.

For now, let us pretend to classify the results into "high energy" and "low energy" usage, where "positive" results correspond to the "high energy" prosumers.
:::

::: {.column width="40%"}
![](Enefit.png)

This Kaggle competition was called "Enefit", and it was created by Eesti Energia to model Estonian energy customers.
:::

::::

## Example

::: {.panel-tabset}

## Confusion Matrix

Suppose that a team of contestants built a machine learning model for this Kaggle competition and achieved the results seen in the confusion matrix below.

```{r}
#| echo: false
#| eval: true

energy_levels <- c("high", "low")
high <- c(59, 14)
low <- c(28, 97)

enefit_df <- data.frame(energy_levels, high, low)

enefit_gt <- enefit_df |>
  gt(rowname_col = "energy_levels") |>
  cols_align(align = "right", columns = energy_levels) |>
  cols_align(align = "center",  columns = c(high, low)) |>
  tab_spanner(columns = c(high, low),
              label = "model predictions") |>
  tab_style(locations = cells_body(columns = high, rows = 1),
            style = list(cell_fill(color = "lightgreen"))) |>
  tab_style(locations = cells_body(columns = low, rows = 2),
            style = list(cell_fill(color = "lightgreen"))) |>
  tab_style(locations = cells_body(columns = high, rows = 2),
            style = list(cell_fill(color = "#FFB3B2"))) |>
  tab_style(locations = cells_body(columns = low, rows = 1),
            style = list(cell_fill(color = "#FFB3B2")))

enefit_gt #display table
```

* true positives: 59
* true negatives: 97
* false positives: 14
* false negatives: 28

## Code

```{r}
#| echo: true
#| eval: false

energy_levels <- c("high", "low")
high <- c(59, 14)
low <- c(28, 97)

enefit_df <- data.frame(energy_levels, high, low)

enefit_gt <- enefit_df |>
  gt(rowname_col = "energy_levels") |>
  cols_align(align = "right", columns = energy_levels) |>
  cols_align(align = "center",  columns = c(high, low)) |>
  tab_spanner(columns = c(high, low),
              label = "model predictions") |>
  tab_style(locations = cells_body(columns = high, rows = 1),
            style = list(cell_fill(color = "lightgreen"))) |>
  tab_style(locations = cells_body(columns = low, rows = 2),
            style = list(cell_fill(color = "lightgreen"))) |>
  tab_style(locations = cells_body(columns = high, rows = 2),
            style = list(cell_fill(color = "#FFB3B2"))) |>
  tab_style(locations = cells_body(columns = low, rows = 1),
            style = list(cell_fill(color = "#FFB3B2")))

enefit_gt #display table
```


## Metrics

For this confusion matrix, compute the accuracy, sensitivity, specificity, and F-score for the results.

```{r}
#| echo: false
#| eval: true

enefit_gt #display table
```


## Formulas

$$\text{accuracy } = \frac{TP + TN}{TP + FN + FP + TN}$$
$$\text{sensitivity } = \frac{TP}{TP + FN}$$
$$\text{specificity } = \frac{TN}{FP + TN}$$
$$\text{F-score } = \frac{2*TP}{2*TP + FN + FP}$$

Source: [Wikipedia page on sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)

:::

::: {.callout-tip collapse="true"}

## Row Span

When these lecture notes were written, there might not have been a function to have a label span multiple rows in the `gt` package.  The left side of the confusion matrix should say "ground truth"

:::

## Practice

Suppose that another team of contestants built a machine learning model for this Kaggle competition and achieved the results seen in the confusion matrix below.

```{r}
#| echo: false
#| eval: true

energy_levels <- c("high", "low")
high <- c(94, 23)
low <- c(80, 939)

enefit_df2 <- data.frame(energy_levels, high, low)

enefit_gt2 <- enefit_df2 |>
  gt(rowname_col = "energy_levels") |>
  cols_align(align = "right", columns = energy_levels) |>
  cols_align(align = "center",  columns = c(high, low)) |>
  tab_spanner(columns = c(high, low),
              label = "model predictions") |>
  tab_style(locations = cells_body(columns = high, rows = 1),
            style = list(cell_fill(color = "lightgreen"))) |>
  tab_style(locations = cells_body(columns = low, rows = 2),
            style = list(cell_fill(color = "lightgreen"))) |>
  tab_style(locations = cells_body(columns = high, rows = 2),
            style = list(cell_fill(color = "#FFB3B2"))) |>
  tab_style(locations = cells_body(columns = low, rows = 1),
            style = list(cell_fill(color = "#FFB3B2")))

enefit_gt2 #display table
```

For this confusion matrix, compute the accuracy, sensitivity, specificity, and F-score for the results.


::: {.callout-warning collapse="true"}

## Prosecutor's Fallacy

For events $A$ and $B$, the inverse conditional probabilities are almost never equal to each other

$$P(A|B) \neq P(B|A)$$

:::

::: {.callout-note collapse="true"}

## (optional) Additional Resources

* [Classical vs Frequentist vs Bayesian Probability](https://www.youtube.com/watch?v=dejy4PPCFHY) by Trefor Bazett

:::